[{"title":"各种数据集到Voc格式","date":"2017-10-23T14:00:39.000Z","path":"2017/10/23/dataset2voc/","text":"各种数据集到Voc格式VOC数据集 这里我们只看有关检测的部分 以VOC2012为例 包含以下文件夹 JPEGImages 存储着图片 Annotations 存储这相关的标签，以xml格式给出,下面为样例 123456789101112131415161718192021222324252627282930313233343536373839&lt;annotation&gt; &lt;folder&gt;VOC2012&lt;/folder&gt; &lt;filename&gt;2007_000392.jpg&lt;/filename&gt; //文件名 &lt;source&gt; //图像来源（不重要） &lt;database&gt;The VOC2007 Database&lt;/database&gt; &lt;annotation&gt;PASCAL VOC2007&lt;/annotation&gt; &lt;image&gt;flickr&lt;/image&gt; &lt;/source&gt; &lt;size&gt; //图像尺寸（长宽以及通道数） &lt;width&gt;500&lt;/width&gt; &lt;height&gt;332&lt;/height&gt; &lt;depth&gt;3&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;1&lt;/segmented&gt; //是否用于分割（在图像物体识别中01无所谓） &lt;object&gt; //检测到的物体 &lt;name&gt;horse&lt;/name&gt; //物体类别 &lt;pose&gt;Right&lt;/pose&gt; //拍摄角度 &lt;truncated&gt;0&lt;/truncated&gt; //是否被截断（0表示完整） &lt;difficult&gt;0&lt;/difficult&gt; //目标是否难以识别（0表示容易识别） &lt;bndbox&gt; //bounding-box（包含左下角和右上角xy坐标） &lt;xmin&gt;100&lt;/xmin&gt; &lt;ymin&gt;96&lt;/ymin&gt; &lt;xmax&gt;355&lt;/xmax&gt; &lt;ymax&gt;324&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; //检测到多个物体 &lt;name&gt;person&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;198&lt;/xmin&gt; &lt;ymin&gt;58&lt;/ymin&gt; &lt;xmax&gt;286&lt;/xmax&gt; &lt;ymax&gt;197&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;/annotation&gt; ImageSets 存放的是每一种类型的challenge对应的图像数据对于检测我们关心的是 里面的Main文件夹，有每一类的train.txt 和val.txt以及test.txt Caltech Pedestrian数据集 这是个行人数据集，数据集提供的图片是以seq的形式存的，标签是以vbb的形式存储的由于原作者是用matlab实现的，因此格式都是以matlab的形式给出。但是我习惯用python，因此查找资料，找到了python版本的转化方式 生成对应图片以及对应的txt格式的标签123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#encoding:utf-8import os, globfrom scipy.io import loadmatfrom collections import defaultdictimport numpy as npfrom xml.dom.minidom import Documentimport cv2import os.path as ospfrom multiprocessing.dummy import Pool as ThreadPooldef vbb_anno2dict(vbb_file, cam_id): filename = os.path.splitext(os.path.basename(vbb_file))[0] annos = defaultdict(dict) vbb = loadmat(vbb_file) # object info in each frame: id, pos, occlusion, lock, posv objLists = vbb['A'][0][0][1][0] objLbl = [str(v[0]) for v in vbb['A'][0][0][4][0]] # person index person_index_list = np.where(np.array(objLbl) == \"person\")[0] for frame_id, obj in enumerate(objLists): if len(obj) &gt; 0: frame_name = str(cam_id) + \"_\" + str(filename) + \"_I\" + str(frame_id).zfill(5) + \".jpg\" annos[frame_name] = defaultdict(list) annos[frame_name][\"id\"] = frame_name annos[frame_name][\"label\"] = \"person\" for id, pos, occl in zip(obj['id'][0], obj['pos'][0], obj['occl'][0]): id = int(id[0][0]) - 1 # for matlab start from 1 not 0 if not id in person_index_list: # only use bbox whose label is person continue pos = pos[0].tolist() occl = int(occl[0][0]) annos[frame_name][\"occlusion\"].append(occl) annos[frame_name][\"bbox\"].append(pos) if not annos[frame_name][\"bbox\"]: del annos[frame_name] return annosanno_trans = &#123;\"person\": \"Pedestrian\"&#125;def seq2img(annos, seq_file, outdir, cam_id): # read .seq file, and save the images into the savepath with open(seq_file,'rb') as f: string = str(f.read()) splitstring = \"\\xFF\\xD8\\xFF\\xE0\\x00\\x10\\x4A\\x46\\x49\\x46\" # split .seq file into segment with the image prefix strlist=string.split(splitstring) index = 1 for img in strlist[:]: v_id = os.path.splitext(os.path.basename(seq_file))[0] cap_frames_index = np.sort([int(os.path.splitext(id)[0].split(\"_\")[2][2:]) for id in annos.keys()]) if not index in cap_frames_index: index += 1 continue outname = os.path.join(outdir, str(cam_id)+\"_\"+v_id+\"_I\"+str(index).zfill(5)+\".jpg\") with open(outname, \"wb+\") as f: f.write(splitstring) f.write(img) index += 1 image_info = dict() image_info[\"height\"] = \"480\" image_info[\"width\"] = \"640\" image_info[\"type\"] = \".jpg\" return image_info #convert anno_file to txt_label def parse_anno_file(vbb_inputdir, seq_inputdir, image_outputdir, txt_label_dir): # annotation sub-directories in hda annotation input directory assert os.path.exists(vbb_inputdir) sub_dirs = os.listdir(vbb_inputdir) for sub_dir in sub_dirs[:]: print \"Parsing annotations of camera: \", sub_dir cam_id = sub_dir vbb_files = glob.glob(os.path.join(vbb_inputdir, sub_dir, \"*.vbb\")) for vbb_file in vbb_files[:]: annos = vbb_anno2dict(vbb_file, cam_id) if annos: seq_file = os.path.join(seq_inputdir, sub_dir, os.path.splitext(os.path.basename(vbb_file))[0]+\".seq\") if not os.path.exists(image_outputdir): os.makedirs(image_outputdir) image_info = seq2img(annos, seq_file, image_outputdir, cam_id) for filename, anno in sorted(annos.items(), key=lambda x: x[0])[:]: if \"bbox\" in anno: name = os.path.splitext(os.path.basename(vbb_file))[0] fullname = os.path.join(txt_label_dir, filename.split(\".\")[0]+\".txt\") with open(fullname, \"ab\") as f: for bbox in anno[\"bbox\"]: print &gt;&gt;f, \"Pedestrian\", bbox[0], bbox[1], bbox[2], bbox[3], 480, 640def main(): dataset_info = &#123;\"name\": \"Caltech\", \"desc\": \"Caltech pedestrian\"&#125; seq_inputdir = \"/home/safe_data_dir/caltech_pedestrian\" vbb_inputdir = \"/home/safe_data_dir/caltech_pedestrian/annotations\" image_outputdir = \"/localSSD/yyq/test\" txt_label_dir = \"/localSSD/yyq/test\" parse_anno_file(vbb_inputdir, seq_inputdir, image_outputdir, txt_label_dir)if __name__ == \"__main__\": main() Caltech2Voc 为了保证和下面保持统一，因此这里先转化一份txt的label，然后用后面的统一脚本转化为xml个的voc格式label Kitti 数据集 KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。标签格式为 Valus Name Description 1 type describes the type of oject 1 truncated float from 0(non-truncated) to 1(truncated) 1 occuded 0 -full visible, 1- partly occluded 2 -largely occluded 3-unknown 1 alpha observation angle of the object 4 bbox 2D bounding bbox of object 3 dimensions 3D dimmensions 3 locations 3D object location 1 rotations Rotation 1 score results Kitti2Voc kitti的标签是以txt的格式给出，每张图片一个txt 标签，我们根据此txt转化为对应的xml即可.为了统一我们先将kitti的txt做一些转化，具体转化生成的txt格式为 type,xmin,ymin,xmax,ymax,height, width.方便后续转xml格式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#encoding:utf-8'''根据一个给定的XML Schema，使用DOM树的形式从空白文件生成一个XML。'''from xml.dom.minidom import Documentimport cv2, osimport os.path as ospfrom multiprocessing.dummy import Pool as ThreadPooldef generate_xml(name, split_lines, class_ind, image_info, dataset_info): doc = Document() #创建DOM文档对象 annotation = doc.createElement('annotation') doc.appendChild(annotation) title = doc.createElement('folder') title_text = doc.createTextNode(dataset_info[\"name\"]) title.appendChild(title_text) annotation.appendChild(title) img_name = name + image_info[\"type\"] title = doc.createElement('filename') title_text = doc.createTextNode(img_name) title.appendChild(title_text) annotation.appendChild(title) source = doc.createElement('source') annotation.appendChild(source) title = doc.createElement('database') title_text = doc.createTextNode(dataset_info[\"desc\"]) title.appendChild(title_text) source.appendChild(title) title = doc.createElement('annotation') title_text = doc.createTextNode(dataset_info[\"name\"]) title.appendChild(title_text) source.appendChild(title) size = doc.createElement('size') annotation.appendChild(size) title = doc.createElement('width') title_text = doc.createTextNode(image_info[\"width\"]) title.appendChild(title_text) size.appendChild(title) title = doc.createElement('height') title_text = doc.createTextNode(image_info[\"height\"]) title.appendChild(title_text) size.appendChild(title) title = doc.createElement('depth') title_text = doc.createTextNode(str(3)) title.appendChild(title_text) size.appendChild(title) for split_line in split_lines: line = split_line.strip().split() if line[0] in class_ind: object = doc.createElement('object') annotation.appendChild(object) title = doc.createElement('name') title_text = doc.createTextNode(line[0]) title.appendChild(title_text) object.appendChild(title) bndbox = doc.createElement('bndbox') object.appendChild(bndbox) title = doc.createElement('xmin') title_text = doc.createTextNode(str(max(0, int(float(line[1]))))) title.appendChild(title_text) bndbox.appendChild(title) title = doc.createElement('ymin') title_text = doc.createTextNode(str(max(0, int(float(line[2]))))) title.appendChild(title_text) bndbox.appendChild(title) title = doc.createElement('xmax') title_text = doc.createTextNode(str(min(image_info[\"width\"], int(float(line[3]))))) title.appendChild(title_text) bndbox.appendChild(title) title = doc.createElement('ymax') title_text = doc.createTextNode(str(min(image_info[\"height\"], int(float(line[4]))))) title.appendChild(title_text) bndbox.appendChild(title) with open(os.path.join(label_xml_dir, name + '.xml'), 'wb') as f: f.write(doc.toprettyxml(indent = '\\t'))def convert(label): filename = label.split(\".\")[0] image_info = &#123;\"type\": \".jpg\"&#125; with open(osp.join(label_txt_dir, label), \"rb\") as f: split_lines = f.readlines() for split_line in split_lines[:1]: line = split_line.strip().split() image_info[\"width\"] = line[-1] image_info[\"height\"] = line[-2] generate_xml(filename, split_lines, class_ind, image_info, dataset_info)if __name__ == '__main__': class_ind=('Pedestrian', 'Car', 'Cyclist') label_txt_dir = \"/your/txt_label_path\" label_xml_dir = \"/your/xml_out_label_path\" dataset_info = &#123;\"name\": \"TCDB\", \"desc\": \"TCDB dataset\"&#125; pool = ThreadPool(processes=20) pool.map(convert, os.listdir(label_txt_dir)) pool.close() pool.join() Tsinghua-Daimler Cyclist Benchmark 清华大学的一个自行车数据集，我们这里只用到其train的数据，数据集链接。其给出的label格式为json格式，比较方便解析 图片分割处理 原生的图片的尺寸为1024x2048，对于我来说太大，而且比例不大合适，因此我决定对图片进行裁剪。决定生成1024x1024的两张图片，只保留包含完整标注的图片和label 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import osimport os.path as ospimport jsonimport cv2import sysimport subprocessfrom multiprocessing.dummy import Pool as ThreadPoollabel_folder = \"/yourpath/tcdb/labelData/train/tsinghuaDaimlerDataset\"image_folder = \"/yourpath/tcdb/leftImg8bit/train/tsinghuaDaimlerDataset\"save_image_folder = \"/yourpath/tcdb/reshape_image\"save_label_folder = \"/yourpath/tcdb/reshape_label\"def convert2txt(origin_label): with open(osp.join(label_folder, origin_label), \"rb\") as f: label_dict = json.load(f) image_name = label_dict[\"imagename\"] bbox_list = label_dict[\"children\"] im = cv2.imread(osp.join(image_folder, image_name)) im_left = im[:,:1024,:] im_left = cv2.resize(im_left, (512, 512)) im_right = im[:,1024:2048,:] im_right = cv2.resize(im_right, (512, 512)) image_id = image_name.split('.')[0] cv2.imwrite(osp.join(save_image_folder, \"\".join([image_id, \"_left\", \".jpg\"])), im_left) cv2.imwrite(osp.join(save_image_folder, \"\".join([image_id, \"_right\", \".jpg\"])), im_right) left_label = open(osp.join(save_label_folder, \"\".join([image_id, \"_left\", \".txt\"])), \"ab\") right_label = open(osp.join(save_label_folder, \"\".join([image_id, \"_right\", \".txt\"])), \"ab\") for bbox in bbox_list: if bbox[\"mincol\"] &gt; 1023: xmin = bbox[\"mincol\"] - 1024 xmax = bbox[\"maxcol\"] - 1024 ymin = bbox['minrow'] ymax = bbox['maxrow'] print &gt;&gt;right_label, \"Cyclist\", xmin / 2, ymin / 2, xmax / 2, ymax / 2, 512, 512 continue if bbox[\"maxcol\"] &lt; 1024: xmin = bbox['mincol'] xmax = bbox['maxcol'] ymin = bbox['minrow'] ymax = bbox['maxrow'] print &gt;&gt;left_label, \"Cyclist\", xmin / 2, ymin / 2, xmax / 2, ymax / 2, 512, 512 continue left_label.close() right_label.close()pool = ThreadPool(processes=20)pool.map(convert2txt, os.listdir(label_folder))pool.close()pool.join()#remove no label txt and imagedef removeNoneLabel(label):# for label in os.listdir(save_label_folder): full_path = os.path.join(save_label_folder, label) img_path = os.path.join(save_image_folder, label.split('.')[0]+\".jpg\") fsize = os.path.getsize(full_path) if fsize == 0: subprocess.call([\"rm\", full_path]) subprocess.call([\"rm\", img_path])pool = ThreadPool(processes=20)pool.map(removeNoneLabel, os.listdir(save_label_folder))pool.close()pool.join() tcdb2Voc 经过前一部分对图片和label进行处理我们最终得到两个文件夹。一个为image存放的是生成的图片，一个是label存放的生成的txt label。我们可以根据之前的脚本生成对应的xml格式 detrac数据集 数据集主要拍摄于北京和天津的道路过街天桥，并手动标注了8250个车辆,标注格式以xml格式给出，但是它是从视频中截帧截出来的，因此一个xml里面包含的是从某个视频截出的所有图片标签。由于test没有标签，我们只用train数据集，包含60个sequences。 生成对应的txt_label1234567891011121314151617181920212223242526#encoding:utf-8import xml.etree.ElementTree as ETimport osimport os.path as ospdef origin_xml2txt(): xml_folder = \"/localSSD/yyq/detrac/DETRAC-Train-Annotations-XML\" label_root = \"/localSSD/yyq/detrac/label\" for xml in os.listdir(xml_folder)[:]: label_folder = osp.join(label_root, xml.split('.')[0]) if not os.path.exists(label_folder): os.makedirs(label_folder) tree = ET.ElementTree(file=osp.join(xml_folder, xml)) root = tree.getroot() for child in root: if 'num' in child.attrib: image_id = \"\".join([\"img\", child.attrib[\"num\"].zfill(5)]) with open(osp.join(label_folder, \"\".join([image_id, \".txt\"])), \"ab\") as fw: for target in child: for bbox in target: xmin = max(0, float(bbox[0].attrib['left'])) ymin = max(0, float(bbox[0].attrib['top'])) xmax = min(float(bbox[0].attrib['left']) + float(bbox[0].attrib[\"width\"]), 960.0) ymax = min(float(bbox[0].attrib['top']) + float(bbox[0].attrib[\"height\"]), 540.0) print &gt;&gt;fw,\"Car\", xmin, ymin, str(xmax), str(ymax), 540, 960 detrac2Voc 根据上面生成的txt_label，再根据txt2xml的脚本生成对应的xml标注。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yqyao.github.io/tags/Linux/"}]},{"title":"Java Serialization","date":"2017-09-09T09:13:17.000Z","path":"2017/09/09/serialize/","text":"Java序列化与反序列化 Java 提供了一种机制，叫做对象序列化，这里对象被描述成一系列包括对象的数据以及有关对象的类型和在对象中存储的数据的类型的字节;ObjectInputStream 和 ObjectOutputStream 类是包含序列化和反序列化对象的方法的流 类序列化类序列化的基本条件 类必须实现 java.io.Serializable 类。 类中所有的字段必须被序列化。如果一个字段没有被序列化，它必须被标记为瞬态的。 如果类实现了 java.io.Serializable，那它就是可序列化的；否则，它就不是。注意对象序列化不会关注类中的静态变量序列化一个对象example123456789101112131415161718192021222324package com.serialize;import java.io.Serializable;@SuppressWarnings(\"serial\")public class Student implements Serializable&#123; public String name; public int score; public String id; public Student(String name, int score, String id) &#123; this.name = name; this.score = score; this.id = id; &#125; @Override public String toString() &#123; return \"Student&#123;\" + \"name='\" + name + '\\'' + \", score=\" + score + \", id=\" + id + '&#125;'; &#125;&#125; 序列化对象到文件中123456789101112131415public class Demo &#123; @Test public void test() &#123; Student student = new Student(\"yao\", 90, \"123344\"); try &#123; FileOutputStream fileout = new FileOutputStream(\"/your/path/student.ser\"); ObjectOutputStream out = new ObjectOutputStream(fileout); out.writeObject(student); out.close(); fileout.close(); &#125; catch(IOException i) &#123; i.printStackTrace(); &#125; &#125;&#125; 反序列化对象123456789101112131415161718192021public class Demo &#123; @Test public void test() &#123; try &#123; FileInputStream fileIn = new FileInputStream(\"/your/path/student.set\"); ObjectInputStream in = new ObjectInputStream(fileIn); Student student = (Student)in.readObject(); in.close(); fileIn.close(); &#125; catch(IOException i) &#123; i.printStackTrace(); return; &#125; catch(ClassNotFoundException c) &#123; c.printStackTrace(); return; &#125; System.out.println(student.name); System.out.println(student.score); System.out.println(student.id); &#125;&#125; 序列化对象到byte[]以及反序列化123456789101112131415161718192021public class Demo &#123; @Test public void test() throws IOException, ClassNotFoundException &#123; Student student = new Student(\"yao\", 80, \"10010\"); ByteArrayOutputStream baops = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baops); oos.writeObject(student); byte[] bytes = baops.toByteArray(); oos.close(); baops.close(); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes)); Student student2 = (Student) ois.readObject(); ois.close(); System.out.println(student2.name); System.out.println(student2.score); System.out.println(student2.id); &#125;&#125; 序列化ArrayList12345678910111213141516171819202122232425public class Demo &#123; @SuppressWarnings(\"unchecked\") @Test public void test() throws IOException, ClassNotFoundException &#123; List&lt;String&gt; stringList = new ArrayList&lt;String&gt;(); stringList.add(\"hello\"); stringList.add(\"world\"); stringList.add(\"hollis\"); stringList.add(\"chuang\"); System.out.println(\"init StringList\" + stringList); ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(\"stringlist\")); objectOutputStream.writeObject(stringList); objectOutputStream.close(); File file = new File(\"stringlist\"); ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file)); List&lt;String&gt; newStringList = (List&lt;String&gt;)objectInputStream.readObject(); objectInputStream.close(); if(file.exists())&#123; file.delete(); &#125; System.out.println(\"new StringList\" + newStringList); &#125;&#125; 需注意 在类中增加writeObject 和 readObject 方法可以实现自定义序列化策略 ArrayList 内部定义了writeObject和readObject方法 在序列化过程中，如果被序列化的类中定义了writeObject 和 readObject 方法，虚拟机会试图调用对象类里的 writeObject 和 readObject 方法，进行用户自定义的序列化和反序列化。如果没有这样的方法，则默认调用是 ObjectOutputStream 的 defaultWriteObject 方法以及 ObjectInputStream 的 defaultReadObject 方法。用户自定义的 writeObject 和 readObject 方法可以允许用户控制序列化的过程，比如可以在序列化的过程中动态改变序列化的数值。 ArrayList 内部writeObject 和 readObject 源码 java.util.ArrayList 源码 ArrayList实现了java.io.Serializable接口，那么我们就可以对它进行序列化及反序列化。因为elementData是transient的，所以我们认为这个成员变量不会被序列化而保留下来 1234567public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; transient Object[] elementData; // non-private to simplify nested class access private int size;&#125; writeObject 1234567891011121314151617private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; readObject 123456789101112131415161718192021private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125; why transient ArrayList实际上是动态数组，每次在放满以后自动增长设定的长度值，如果数组自动增长长度设为100，而实际只放了一个元素，那就会序列化99个null元素。为了保证在序列化的时候不会将这么多null同时进行序列化，ArrayList把元素数组设置为transient why writeObject and readObject 为了防止一个包含大量空对象的数组被序列化，为了优化存储，所以，ArrayList使用transient来声明elementData。 但是，作为一个集合，在序列化过程中还必须保证其中的元素可以被持久化下来，所以，通过重写writeObject 和 readObject方法的方式把其中的元素保留下来。writeObject方法把elementData数组中的元素遍历的保存到输出流（ObjectOutputStream）中。readObject方法从输入流（ObjectInputStream）中读出对象并保存赋值到elementData数组中。","tags":[{"name":"Java","slug":"Java","permalink":"http://yqyao.github.io/tags/Java/"}]},{"title":"libcurl 使用","date":"2017-08-04T00:42:00.000Z","path":"2017/08/04/libcurl_use/","text":"c++ httpclient 介绍前言 由于工程使用的c++，而且需要用到http，在c++中使用较为广泛的是libcurl这个库，在查阅了一部分资料之后在此做个总结。同时这里也查了关于Json的使用方式，使用库为jsoncpp libcurl介绍 libcurl是一个跨平台的网络协议库，支持http, https, ftp, gopher, telnet, dict, file, 和ldap 协议。libcurl同样支持HTTPS证书授权，HTTP POST, HTTP PUT, FTP 上传, HTTP基本表单上传，代理，cookies,和用户认证。官网地址 http://curl.haxx.se/ 下载安装123456wget http://curl.haxx.se/download/curl-7.54.1.tar.gztar -zxvf curl-7.54.1.tar.gzcd curl-7.54.1./configure --prefix=/your/pathmakemake install 基本函数说明CURLcode curl_global_init(long flags) 基本概念 这个函数只能用一次。(其实在调用curl_global_cleanup 函数后仍然可再用)如果这个函数在curl_easy_init调用时还没被调用，它将由libcurl库自动调用，为了避免一些不必要的问题，建议主动调该函数，以防止多次调用。同时需要注意的是curl_global_init是不能保证线程安全的。 主要参数(flag) CURL_GLOBAL_ALL //初始化所有的可能的调用 CURL_GLOBAL_SSL //初始化支持 安全套接字层。 CURL_GLOBAL_WIN32 //初始化win32套接字库 CURL_GLOBAL_NOTHING //没有额外的初始化。 void curl_global_cleanup(void) 描述：在结束libcurl使用的时候，用来对curl_global_init做的工作清理。类似于close的函数。注意：虽然libcurl是线程安全的，但curl_global_cleanup是不能保证线程安全的，所以不要在每个线程中都调用curl_global_init，应该将该函数的调用放在主线程中。 CURL *curl_easy_init( ); curl_easy_init用来初始化一个CURL的指针(有些像返回FILE类型的指针一样). 相应的在调用结束时要用curl_easy_cleanup函数清理.一般curl_easy_init意味着一个会话的开始. 它会返回一个easy_handle(CURL*对象), 一般都用在easy系列的函数中. void curl_easy_cleanup(CURL *handle); 配合curl_easy_init() 使用，用于结束一个会话 CURLcode curl_easy_setopt(CURL *handle, CURLoption option, parameter); 这个函数最重要了.几乎所有的curl 程序都要频繁的使用它.它告诉curl库.程序将有如何的行为. 参数 CURL类型的指针 CURLoption类型的选项( 后续会有介绍) parameter，具体什么类型取决于第二个参数类型 CURLcode curl_easy_perform(CURL *handle) 实际运行函数，返回值表示是否成功，0表示成功其他都表示失败 curl_easy_setopt 函数介绍 CURLOPT_URL 设置访问的URL CURLOPT_WRITEFUNCTION，CURLOPT_WRITEDATA 回调函数原型为size_t function( void ptr, size_t size, size_t nmemb, void stream)；函数将在libcurl接收到数据后被调用，因此函数多做数据保存的功能，我们可以设置保存数据到自己定义的结构体，也可以保存到文件当中。CURLOPT_WRITEDATA 用于表明CURLOPT_WRITEFUNCTION函数中的stream指针的来源。如果没有设置CURLOPT_WRITEFUNCTION回调函数，默认的回调函数是将输出打印到标准输出。 CURLOPT_HEADERFUNCTION，CURLOPT_HEADERDATA 同上面的一样,不过设置是Header数据 CURLOPT_READFUNCTION CURLOPT_READDATA libCurl需要读取数据传递给远程主机时将调用CURLOPT_READFUNCTION指定的函数，函数原型是：size_t function(void ptr, size_t size, size_t nmemb,void stream). CURLOPT_READDATA 表明CURLOPT_READFUNCTION函数原型中的stream指针来源 CURLOPT_TIMEOUT，CURLOPT_CONNECTIONTIMEOUT CURLOPT_TIMEOUT 由于设置传输时间，CURLOPT_CONNECTIONTIMEOUT 设置连接等待时间 CURLOPT_FOLLOWLOCATION 设置重定位URL curl_easy_perform 函数说明0 表示一切ok, 非0代表错误发生 CURLE_OK –任务完成 CURLE_UNSUPPORTED_PROTOCOL –不支持的协议 CURLE_COULDNT_CONNECT –无法连接remote主机 CURLE_REMOTE_ACCESS_DENIED –访问被拒绝 CURLE_HTTP_RETURNED_ERROR –http返回错误 CURLE_READ_ERROR –读本地文件错误 HTTP消息头设置 基本概念 当使用libcurl发送http请求时，它会自动添加一些http头。我们可以通过CURLOPT_HTTPHEADER属性手动替换、添加或删除相应 的HTTP消息头. 基本设置 以POST的方式向HTTP服务器提交请求时，libcurl会设置该消息头为”100-continue”，它要求服务器在正式处理该请求之前，返回一 个”OK”消息。如果POST的数据很小，libcurl可能不会设置该消息头。 自定义请求方式 HTTP支持GET, HEAD或者POST提交请求。可以设置CURLOPT_CUSTOMREQUEST来设置自定义的请求方式，libcurl默认以GET方式提交请求：比如我们想用PUT请求curl_easy_setopt(easy_handle, CURLOPT_CUSTOMREQUEST, “PUT”); 如何添加删除消息头 后面程序会有介绍 获取http应答头信息 基本概念 发出http请求后，服务器会返回应答头信息和应答数据，如果仅仅是打印应答头的所有内容，则直接可以通过curl_easy_setopt(curl, CURLOPT_HEADERFUNCTION, 打印函数)的方式来完成，这里需要获取的是应答头中特定的信息，比如应答码、cookies列表等，则需要通过下面这个函数: CURLcode curl_easy_getinfo(CURL *curl, CURLINFO info, … ) 参数 CURLINFO_RESPONSE_COD –获取应答码 CURLINFO_HEADER_SIZE –头大小 CURLINFO_COOKIELIST –cookies列表 其他根据需要查看官方文档 密码登陆 支持URL直接指定用户名和密码的协议 curl_easy_setopt(easy_handle, CURLOPT_USERPWD, “user_name:password”); 访问代理服务器 curl_easy_setopt(easy_handle, CURLOPT_PROXYUSERPWD, “user_name:password”) FTP 访问 curl_easy_setopt(easy_handle, CURLOPT_NETRC, 1L);从&amp;HOME/.netrc 文件中获取用户名和密码 SSL访问 curl_easy_setopt(easy_handle, CURLOPT_KEYPASSWD, “keypassword”);通过这个来设置私钥 HTTP验证 基本概念 在使用HTTP协议时，客户端有很多种方式向服务器提供验证信息。默认的 HTTP验证方法是”Basic”，它将用户名与密码以明文的方式、经Base64编码后保存在HTTP请求头中，发往服务器。当然这不太安全. libcurl 支持验证方式 basic, Digest, NTLM, Negotiate, GSS-Negotiate and SPNEGO(具体可以查找资料)。用户可以通过CURLOPT_HTTPAUTH属性来设置具体的验证方式。 直接发给服务器 curl_easy_setopt(easy_handle, CURLOPT_HTTPAUTH, CURLAUTH_DIGEST); 发给代理服务器 curl_easy_setopt(easy_handle, CURLOPT_PROXYAUTH, CURLAUTH_NTLM); 多线程线程安全 基本概念 绝对不应该在线程之间共享同一个libcurl handle(CURL *对象)，不管是easy handle还是multi handle。一个线程每次只能使用一个handle. 多线程设置 CURLcode curl_easy_setopt(CURL *handle, CURLOPT_NOSIGNAL, long onoff);多线程使用中，为了线程安全一般设置onoff为1 示例代码官方示例代码 123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt; #include &lt;curl/curl.h&gt; bool getUrl(char *filename) &#123; CURL *curl; CURLcode res; FILE *fp; if ((fp = fopen(filename, \"w\")) == NULL) // 返回结果用文件存储 return false; struct curl_slist *headers = NULL; headers = curl_slist_append(headers, \"Accept: Agent-007\"); curl = curl_easy_init(); // 初始化 if (curl) &#123; //curl_easy_setopt(curl, CURLOPT_PROXY, \"10.99.60.201:8080\");// 代理 curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);// 改协议头 curl_easy_setopt(curl, CURLOPT_URL,\"http://www.baidu.com\"); curl_easy_setopt(curl, CURLOPT_WRITEDATA, fp); //将返回的http头输出到fp指向的文件 curl_easy_setopt(curl, CURLOPT_HEADERDATA, fp); //将返回的html主体数据输出到fp指向的文件 res = curl_easy_perform(curl); // 执行 if (res != 0) &#123; curl_slist_free_all(headers); curl_easy_cleanup(curl); &#125; fclose(fp); return true; &#125; &#125; int main(void) &#123; getUrl(\"get.html\"); &#125; Json使用jsoncpp 安装123456git clone https://github.com/open-source-parsers/jsoncpp#generating-amalgamated-source-and-headercd jsoncppcmake .make make install 注意根据官网的介绍，还要运行下面的程序更新一些必要文件 1python amalgamate.py 生成文件 dist/jsoncpp.cpp –此文件需要加入到你的project当中 dist/json/json.h –相关头文件 dist/json/json-forwards.h 使用方式json对象生成 第一种方式 1234Json::Value root;root[\"name\"] = \"yyq\";root[\"id\"] = 3;string json = root.toStyledString(); //生成字符串 第二种方式 12345Json::Value root;root[\"name\"].append(\"yao\");root[\"name\"].append(\"li\"); //name 对应则是一个listroot[\"id\"] = 3;string json = root.toStyledString(); //生成字符串 第三种方式 123456Json::Value root; root[\"id\"] = 1; root[\"data\"][\"name\"] = \"wu\"; root[\"data\"][\"age\"] = 26; std::string json = root.toStyledString(); json文件写入123456789101112131415161718Json::Value root;Json::Reader reader;Json::FastWriter fwriter; //FastWriter就是无格式的写入Json::StyledWriter swriter; //而StyledWriter就是带有格式的写入if(! reader.parse(\"example.json\", root))&#123;// parse fail return 0;&#125;std::string str = fwriter(root);std::ofstream ofs(\"example_fast_writer.json\");ofs &lt;&lt; str;ofs.close();str = swriter(root);ofs.open(\"example_styled_writer.json\");ofs &lt;&lt; str;ofs.close(); json格式解析字符串12345678910111213string json = \"&#123;\\\"id\\\" : 1, \\\"data\\\" : &#123; \\\"name\\\" : \\\"wu\\\", \\\"age\\\" : 26 &#125; &#125;\"; Json::Reader reader; Json::Value root; std::string name; int id = 0; int age = 0; if (reader.parse(json, root)) // reader将Json字符串解析到root，root将包含Json里所有子元素 &#123; id = root[\"id\"].asInt(); name = root[\"data\"][\"name\"].asString(); age = root[\"data\"][\"age\"].asInt(); &#125; json格式解析文件123456789101112Json::Value root;Json::Reader reader;ifstream ifs(\"example.json\");//open file example.jsonif(!reader.parse(ifs, root))&#123; // fail to parse&#125;else&#123; // success cout &lt;&lt; root[\"encoding\"].asString() &lt;&lt; endl; cout &lt;&lt; root[\"indent\"][\"length\"].asInt() &lt;&lt; endl;&#125; 其他操作 判断key是否存在 1234bool Json::Value::isMember ( const std::string &amp; key) constbool Json::Value::isMember ( const char* key, const char * end ) constJson::Value root;bool exist = root.isMember(\"name\") 判断值是否为Null 123bool Json::Value::isNull() constJson::Value root;bool isnull = root[\"name\"].isNull() 得到所有的key 12Value::Members Json::Value::getMemberNames ( ) constReturn a list of the member names 删除成员 1234567Value Json::Value::removeMember( const char* key) Remove and return the named member.Do nothing if it did not exist.Returns the removed Value, or null. libcurl发送Json数据完整代码github代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;stdio.h&gt; #include &lt;curl/curl.h&gt;#include &lt;dist/json/json.h&gt;#include &lt;dist/json/json-forwards.h&gt;#include &lt;dist/jsoncpp.cpp&gt;#include &lt;typeinfo&gt;#include &lt;iostream&gt;int postUrlJson(const string url, const string &amp; postStr, string &amp;response)&#123; CURL *curl; CURLcode res; struct curl_slist *headers = NULL; headers = curl_slist_append(headers, \"Accept: */*\"); headers = curl_slist_append(headers, \"Host: localhost\"); headers = curl_slist_append(headers, \"Content-Type: application/json\"); // // headers = curl_slist_append(headers, \"Host:\") remove the headers of host curl = curl_easy_init(); // 初始化 if (curl) &#123; curl_easy_setopt(curl, CURLOPT_POSTFIELDS, postStr.c_str()); // 指定post内容 //curl_easy_setopt(curl, CURLOPT_PROXY, \"10.99.60.201:8080\"); curl_easy_setopt(curl, CURLOPT_URL, url.c_str()); // 指定url curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, OnWriteData); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void*)&amp;response); // curl_easy_setopt(curl, CURLOPT_HEADERDATA, fp); res = curl_easy_perform(curl); if (res != 0) &#123; curl_slist_free_all(headers); curl_easy_cleanup(curl); return -1; &#125; stringToJson(response); cout &lt;&lt; \"post json response:\\t\" &lt;&lt; response &lt;&lt; endl; return 0; &#125; return -1; &#125;Json::Value stringToJson(string str)&#123; Json::Reader reader; Json::Value root; if (reader.parse(str, root)) &#123; if (!root[\"name\"].isNull()) &#123; string strValue= root[\"name\"].asString(); cout &lt;&lt; strValue &lt;&lt; endl; &#125; &#125;&#125;string postJsonStr()&#123; //从server端返回的json数据 Json::Value root; root[\"post_json\"] = \"json\"; root[\"post_id\"] = 3; return root.toStyledString();&#125;int main()&#123; string post_json_url = \"http://localhost:8089/post_json\"; string post_json_rep; httpclient-&gt;postUrlJson(post_json_url, postJsonStr(), post_json_rep); return 0;&#125;","tags":[{"name":"libcurl","slug":"libcurl","permalink":"http://yqyao.github.io/tags/libcurl/"}]},{"title":"zookeeper_use","date":"2017-07-30T03:13:17.000Z","path":"2017/07/30/zk_use/","text":"Zookeeper Curator用法指南前言 原生Zookeeper 提供了一套接口供我们使用，但是非常不辛的是，原生的接口太容易出现错误。因此在实际使用中我们一般不使用原始Zookeeper Api进行调用。Curator框架提供了一套高级的API，方便了Zookeeper的操作。它增加了使用Zookeeoper开发的特性。可以处理Zookeeper集群复杂的连接管理和重试机制。同时它也封装好了一些常用的recipes，方便我们直接调用。 Curator 基本用法 Curator框架通过CuratorFrameworkFactory通过工厂模式和builder模式来创建CuratorFramework实例。需要注意的是CuratorFramework实例都是线程安全的，因此我们在程序中只需要共享一个实例即可。 功能组件 Framework Framework 提供了一套高级的API， 简化了ZooKeeper的操作。 它增加了很多使用ZooKeeper开发的特性，可以处理ZooKeeper集群复杂的连接管理和重试机制 Client 是ZooKeeper客户端的一个替代品,提供了一些底层处理和相关的工具方法 Recipes 实现了通用ZooKeeper的recipe,该组件建立在Framework的基础之上.例如，master选举，分布式锁等等 Utilities 各种工具类 Errors 异常处理，连接，恢复 Extensions curator-recipes 实现了通用的技巧 Curator 创建 此例子是以builder的方式创建，这样可以加入更多的参数控制。 1234567891011121314151617181920212223package com.master;import org.apache.curator.RetryPolicy;import org.apache.curator.framework.CuratorFramework;public class Master &#123; public static final String CONNECTION_STRING = \"localhost:2181\"; public static final String MASTER_PATH = \"/taskJobs\"; private static CuratorFramework getClient() &#123; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(CONNECTION_STRING) .retryPolicy(retryPolicy) .sessionTimeoutMs(100) .connectionTimeoutMs(100) .build(); client.start(); return client; &#125; public static void main(String args[]) throws Exception &#123; CuratorFramework client = getClient(); &#125; &#125; CuratorFramework 具体方法简介 create() 创建操作 delete() 删除操作 checkExists() 检查znode 节点是否存在 getData() 获取znode节点内容 setData() 设置znode节点内容 getChildren() 获得znode节点内容子节点列表 具体如何使用，后面有程序示例 https://github.com/yqyao/MyGit/tree/master/Zookeeper 12345678910111213141516171819202122232425262728293031323334353637383940package com.curator.test;import java.util.ArrayList;import java.util.List;import org.apache.curator.RetryPolicy;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.framework.api.BackgroundCallback;import org.apache.curator.framework.api.CuratorEvent;import org.apache.curator.framework.api.CuratorListener;import org.apache.curator.framework.recipes.cache.NodeCache;import org.apache.curator.framework.recipes.cache.NodeCacheListener;import org.apache.curator.framework.recipes.cache.PathChildrenCache;import org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;import org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.curator.utils.ZKPaths;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.Watcher;public class CuratorExample &#123; public static final String CONNECTION_STRING = \"101.201.118.55:2181\"; public static final String TEST_PATH = \"/tests\"; public static final String CHILDREN_PATH = \"/tests/children\"; public static CuratorFramework getClient() &#123; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(CONNECTION_STRING) .retryPolicy(retryPolicy) .sessionTimeoutMs(100) .connectionTimeoutMs(100) .build(); client.start(); return client; &#125; ... ... &#125; 客户端代码 1234567891011121314151617181920212223242526272829303132333435363738394041package load_leveling;import java.util.ArrayList;import java.util.List;import java.util.Random;import org.apache.curator.RetryPolicy;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.retry.ExponentialBackoffRetry;public class ApiCaller &#123; private static final String CONNECT_STRING = \"localhost:2181\"; private static final String ZK_PATH = \"/servers\"; public static void getServer(CuratorFramework client) &#123; List&lt;String&gt; allServer = new ArrayList&lt;String&gt;(); try &#123; allServer = client.getChildren().forPath(ZK_PATH); Random r = new Random(); int temp = r.nextInt(2); System.out.println(allServer.get(temp)); byte[] data = client.getData().forPath(ZK_PATH+\"/\"+allServer.get(temp)); System.out.println(new String(data)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String [] args) &#123; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.newClient( CONNECT_STRING, retryPolicy ); client.start(); getServer(client); &#125;&#125; 注意这里选择的选择节点策略为随机选择一个节点。具体使用可以采取其他策略","tags":[{"name":"Java","slug":"Java","permalink":"http://yqyao.github.io/tags/Java/"}]},{"title":"Jersey_use","date":"2017-07-30T03:13:17.000Z","path":"2017/07/30/Jersey/","text":"Jersey Restful框架使用前言 由于之前使用python 的Tornado这个web 框架，了解到了一些有关Restful API知识，但是python这个语言在web 开发中不是太擅长。而Java 在web开发中则用的比较多，因此在查阅了一系列资料之后，发现Jersey这个轻量级的Restful API框架，配合Tomcat可以构成简单的Web开发。趁着放假，找了一些资料进行了简单的学习。可能以后会用到，因此想记录下来学习过程。以后重新拾起的时候希望会快速入门。 Jersey 介绍 Jersey RESTful 框架是开源的RESTful框架, 实现了JAX-RS (JSR 311 &amp; JSR 339) 规范。它扩展了JAX-RS 参考实现， 提供了更多的特性和工具， 可以进一步地简化 RESTful service 和 client 开发。尽管相对年轻，它已经是一个产品级的 RESTful service 和 client 框架。对于轻量级应用来说，这个是非常好的选择。 配置版本 Jersey2.x Tomcat7.x maven3.5.0 java8 eclipse 实际使用基础配置 maven Web工程建立和Tomcat 配置 本文就不介绍了，这个可以百度，教程也很多。 Jersey使用maven下载对应依赖库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;mygroup.com&lt;/groupId&gt; &lt;artifactId&gt;myprojectname&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;myprojectname Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.containers&lt;/groupId&gt; &lt;artifactId&gt;jersey-container-servlet-core&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.ws&lt;/groupId&gt; &lt;artifactId&gt;jaxws-api&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.containers&lt;/groupId&gt; &lt;artifactId&gt;jersey-container-servlet-core&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.jaxrs&lt;/groupId&gt; &lt;artifactId&gt;jackson-jaxrs-json-provider&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;tomcat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/test&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;url&gt;http://localhost:80/test&lt;/url&gt; &lt;server&gt;tomcat7&lt;/server&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;finalName&gt;myprojectname&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; Web 配置123456789101112131415161718192021222324&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt; &lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;jersey-serlvet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.glassfish.jersey.servlet.ServletContainer&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;jersey.config.server.provider.packages&lt;/param-name&gt; &lt;param-value&gt;test&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;jersey-serlvet&lt;/servlet-name&gt; &lt;url-pattern&gt;/test/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; server基本参数说明 @Path 标注资源类或者方法的相对路径 @GET，@PUT，@POST，@DELETE 标注方法是HTTP请求的类型 Produces 标注返回的MIME媒体类型, 例如MediaType.APPLICATION_JSON，MediaType.TEXT_PLAIN，MediaType.APPLICATION_XML Consumes 标注可接受请求的MIME媒体类型，和上面的类型一样 Demogithub: https://github.com/yqyao/MyGit/tree/master/Jersey Student 代码见github Server 端 12345678910111213141516171819202122232425262728293031323334package test;import java.util.HashMap;import java.util.Map;import javax.ws.rs.Consumes;import javax.ws.rs.GET;import javax.ws.rs.POST;import javax.ws.rs.PUT;import javax.ws.rs.Path;import javax.ws.rs.Produces;import javax.ws.rs.core.Form;import javax.ws.rs.core.MediaType;import javax.ws.rs.core.MultivaluedMap;@Path(\"/\")public class JerseyServer &#123; private static Map&lt;Integer, Student&gt; students = new HashMap&lt;Integer, Student&gt;(); @GET @Path(\"/get_text\") @Produces(MediaType.TEXT_PLAIN) public String getText() &#123; return \"get text test\"; &#125; @GET @Path(\"/get_json\") @Produces(MediaType.APPLICATION_JSON) public String getJson() &#123; Student student = new Student(1, \"get_json\"); return student.toString(); &#125;&#125; Client 端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package test;import javax.ws.rs.client.Client;import javax.ws.rs.client.ClientBuilder;import javax.ws.rs.client.Entity;import javax.ws.rs.client.WebTarget;import javax.ws.rs.core.Form;import javax.ws.rs.core.MediaType;import javax.ws.rs.core.Response;public class JerseyClient &#123; public final static String get_text_path = \"http://localhost:80/WebProject/test/get_text\"; public static Client client = ClientBuilder.newClient(); public static void getText() &#123; WebTarget target = client.target(get_text_path); Response response = target.request().get(); try &#123; if (response.getStatus() != 200) &#123; System.out.println(\"status error\"); &#125; System.out.println(response.readEntity(String.class)); &#125; finally &#123; response.close(); &#125; &#125; public static void getJson() &#123; WebTarget target = client.target(get_json_path); Response response = target.request().get(); try &#123; if (response.getStatus() != 200) &#123; System.out.println(response.getStatus()); System.out.println(\"status error\"); &#125; System.out.println(response.readEntity(String.class)); &#125; finally &#123; response.close(); &#125; &#125; public static void main(String args[]) &#123; getText(); getJson(); client.close(); &#125; &#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://yqyao.github.io/tags/Java/"}]},{"title":"Mysql++ 使用","date":"2017-07-26T12:42:00.000Z","path":"2017/07/26/mysql++/","text":"Mysql++ 使用记录前言最近因为要使用mysql 的c接口，查了好多资料发现网上关于mysql的c 资料是真的不多。不过还好查到了一个Mysql++这个库，可以方便我更好的进行开发。但是即使这样，其使用难度也比一般的Java和python接口要难得多，因此非常有必要记录一下这几天查到的资料，做一个简单的总结。 Mysql ++ 连接安装123456# http://tangentsoft.net/mysql++/，从官网下载稳定版本mysql++-3.2.3.tar.gztar -zxvf mysql++-3.2.3.tar.gzcd mysql++-3.2.3./configure --prefix=/your/install/pathmakemake install 原始连接方式我们可以采取最原始的连接方式，也比较简单。 123456789101112131415161718192021222324include &lt;mysql++.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;typeinfo&gt;using namespace std;using namespace mysqlpp;#define DATEBASE_NAME \"search\"#define DATEBASE_IP \"localhost:3306\"#define DATEBASE_USERNAME \"root\"#define DATEBASE_PWD \"DeepLearning\"int main()&#123; Connection conn(false); if(conn.connect(DATEBASE_NAME, DATEBASE_IP, DATEBASE_USERNAME, DATEBASE_PWD)) cout &lt;&lt; \"connect success !!!\" &lt;&lt; endl; Query query = conn.query(); char* sql = \"select * from test\"; query &lt;&lt; sql; return 0;&#125; 连接池使用 连接池这个概念在数据库使用中常常会用到，对于一般的使用，对于数据库的访问不是太频繁我们可以每次建立连接，使用完就释放连接。但是对于一个复杂的数据库应用，情况就完全不同了，频繁的建立、关闭连接，会极大的减低系统的性能，因为对于连接的使用成了系统性能的瓶颈。连接池的原理是先在内部建立好很多连接，用户使用的时候直接从连接池中获取连接即可，用户使用完再归还连接，但是连接并没有别断开，而是为下一次使用做准备。 mysql++ 内部已经实现好连接池 mysql++-3.2.3/lib/cpool.cpp 这是源码文件 123456virtual Connection* exchange(const Connection* pc); //将当前连接断开重新开启一个连接virtual Connection* grab(); //从连接池获取一个连接，如果没有创建一个Connection* safe_grab(); //从连接池获取一个可用的连接virtual void release(const Connection* pc); //将一个连接置为未使用状态void shrink() //从连接池删除未使用的连接void remove(const Connection* pc) //从连接池中删除指定连接 继承mysqlpp::ConnectionPool 实现自己的连接池 1234567891011121314151617181920212223242526class MysqlConnectPool : public mysqlpp::ConnectionPool&#123;public: MysqlConnectPool(std::string dbname, std::string serverip, std::string user, std::string passwd, int port, std::string charset, int max_size) :m_dbname(dbname) ,m_server_ip(serverip) ,m_user(user) ,m_password(passwd) ,m_charset(charset) ,m_port(port) &#123; m_max_size = max_size; conns_in_use_ = 0; m_max_idle_time = 300; &#125; ······ ·····//代码太多，暂时就不贴了。。。https://github.com/yqyao/MyGit/tree/master/mysql_c%2B%2B这个github有&#125; mysql++ API调用方式 输入处理 123456789101112131415161718192021222324252627282930313233343536#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;# include \"unistd.h\"#include \"MysqlConnectPool.h\"std::shared_ptr&lt;MysqlConnectPool&gt; db_pool = nullptr;std::string db_name = \"search\";std::string db_ip = \"localhost\";std::string db_user = \"root\";std::string db_passwd = \"DeepLearning\";int db_port = 3306;std::string db_charset = \"utf8\";int max_size = 10;int BUFF_SIZE = 1024;char buff[1024];char* createTableFormat = \"create table %s ;\";std::string getCreateString()&#123; memset(buff, 0, BUFF_SIZE); char* temp = \"Student(id int, name varchar(20), status varchar(10))\"; snprintf(buff, sizeof(buff), createTableFormat, temp); std::string buffAsStdStr = buff; return buffAsStdStr;&#125;int main()&#123; db_pool = std::make_shared&lt;MysqlConnectPool&gt;(db_name, db_ip, db_user, db_passwd, db_port, db_charset, max_size); std::string createTablesql = getCreateString(); std::cout &lt;&lt; \"createTableFormat: \" &lt;&lt; createTablesql &lt;&lt; std::endl; //out:createTableFormat: create table Student(id int, name varchar(20), status varchar(10))&#125; 实际执行过程 12345678910111213141516void createTable(std::string sql)&#123; mysqlpp::ScopedConnection conn(*db_pool, false); mysqlpp::Query query = conn-&gt;query(); query &lt;&lt; sql; mysqlpp::SimpleResult res = query.execute(); std::cout &lt;&lt; res.info() &lt;&lt; std::endl;&#125;int main()&#123; db_pool = std::make_shared&lt;MysqlConnectPool&gt;(db_name, db_ip, db_user, db_passwd, db_port, db_charset, max_size); std::string createTablesql = getCreateString(); std::cout &lt;&lt; \"createTableFormat: \" &lt;&lt; createTablesql &lt;&lt; std::endl; createTablesql(createTablesql); //out:createTableFormat: create table Student(id int, name varchar(20), status varchar(10))&#125; 因为select 操作涉及到数据取出，因此需要重点介绍 search操作 表结构为上一步介绍create所创建的结构12345678910111213141516171819202122232425262728293031std::string getSearchString()&#123; memset(buff, 0, BUFF_SIZE); char* status = \"false\"; snprintf(buff, sizeof(buff), searchFormat, status); std::string buffAsStdStr = buff; return buffAsStdStr;&#125;void search(std::string sql)&#123; //this scopedConnection will get the connection and release the connection to the connection pool after ~scopedConnection mysqlpp::ScopedConnection conn(*db_pool, false); mysqlpp::Query query = conn-&gt;query(); query &lt;&lt; sql; mysqlpp::StoreQueryResult ares = query.store(); std::cout &lt;&lt; \"ares.num_rows() = \" &lt;&lt; ares.num_rows() &lt;&lt; std::endl; for (size_t i = 0; i &lt; ares.num_rows(); i++) &#123; std::cout &lt;&lt; \"your data\" &lt;&lt; std::endl; std::cout &lt;&lt; \"name: \" &lt;&lt; ares[i][\"name\"] &lt;&lt; \"\\tid: \" &lt;&lt; ares[i][\"id\"] &lt;&lt; \"\\tstatus: \" &lt;&lt; ares[i][\"status\"] &lt;&lt; std::endl; &#125;&#125;int main()&#123; db_pool = std::make_shared&lt;MysqlConnectPool&gt;(db_name, db_ip, db_user, db_passwd, db_port, db_charset, max_size); std::string searchSql = getSearchString(); std::cout &lt;&lt; \"searchFormat: \" &lt;&lt; searchSql &lt;&lt; std::endl; search(searchSql); return 0;&#125; 注意事项 我们这里的使用的是Mysql++ 官方使用的scopedConnection 类自动获取conn，同时利用析构函数去release conn。我们也可以直接使用原始api去使用这个连接。 1234567891011int main()&#123; db_pool = std::make_shared&lt;MysqlConnectPool&gt;(db_name, db_ip, db_user, db_passwd, db_port, db_charset, max_size); const char* search = \"select * from yyq\"; mysqlpp::Connection* conn; conn = db_pool-&gt;grab(); db_pool-&gt;release(conn); //将conn放回连接池 db_pool-&gt;remove(conn); //将conn从连接池去除 std::cout &lt;&lt; db_pool-&gt;getSize() &lt;&lt; std::endl; //当前连接池连接个数&#125; 这种方式调用连接池的时候需要注意，每次使用完conn连接后需要手动的去release这个连接，不然连接池会重复的建立新连接，达不到我们需要的效果。","tags":[{"name":"Mysql++","slug":"Mysql","permalink":"http://yqyao.github.io/tags/Mysql/"}]},{"title":"zookeeper","date":"2017-07-01T03:13:17.000Z","path":"2017/07/01/zookeeper/","text":"Zookeeper学习 基本概念 数据节点 zk数据模型中的最小数据单元，数据模型是一棵树，由斜杠（/）分割的路径名唯一标识，数据节点可以存储数据内容及一系列属性信息，同时还可以挂载子节点，构成一个层次化的命名空间，相比Unix的文件节点，zk中的数据节点既是目录也是文件。 会话 指zk客户端与zk服务器之间的会话，在zk中，会话是通过客户端和服务器之间的一个TCP长连接来实现的。通过这个长连接，客户端能够使用心跳检测与服务器保持有效的会话，也能向服务器发送请求并接收响应，还可接收服务器的Watcher事件通知。Session的sessionTimeout，是会话超时时间，如果这段时间内，客户端未与服务器发生任何沟通（心跳或请求），服务器端会清除该session数据，客户端的TCP长连接将不可用，这种情况下，客户端需要重新实例化一个Zookeeper对象 事务 事务是指能够改变Zookeeper服务器状态的操作，一般包括数据节点的创建与删除、数据节点内容更新和客户端会话创建与失效等操作。对于每个事务请求，zk都会为其分配一个全局唯一的事务ID，即ZXID，是一个64位的数字，高32位表示该事务发生的集群选举周期（集群每发生一次leader选举，值加1），低32位表示该事务在当前选择周期内的递增次序（leader每处理一个事务请求，值加1，发生一次leader选择，低32位要清0） 事务日志 所有事务操作都是需要记录到日志文件中的，可通过dataLogDir配置文件目录，文件是以写入的第一条事务zxid为后缀，方便后续的定位查找。zk会采取“磁盘空间预分配”的策略，来避免磁盘Seek频率，提升zk服务器对事务请求的影响能力。默认设置下，每次事务日志写入操作都会实时刷入磁盘，也可以设置成非实时（写到内存文件流，定时批量写入磁盘），但那样断电时会带来丢失数据的风险 数据快照 数据快照是zk数据存储中另一个非常核心的运行机制。数据快照用来记录zk服务器上某一时刻的全量内存数据内容，并将其写入到指定的磁盘文件中，可通过dataDir配置文件目录。可配置参数snapCount，设置两次快照之间的事务操作个数，zk节点记录完事务日志时，会统计判断是否需要做数据快照（距离上次快照，事务操作次数等于snapCount/2~snapCount 中的某个值时，会触发快照生成操作，随机值是为了避免所有节点同时生成快照，导致集群影响缓慢） 过半 所谓“过半”是指大于集群机器数量的一半，即大于或等于（n/2+1），此处的“集群机器数量”不包括observer角色节点。leader广播一个事务消息后，当收到半数以上的ack信息时，就认为集群中所有节点都收到了消息，然后leader就不需要再等待剩余节点的ack，直接广播commit消息，提交事务。选举中的投票提议及数据同步时，也是如此，leader不需要等到所有learner节点的反馈，只要收到过半的反馈就可进行下一步操作 Zookeeper分布式特性 顺序一致性 从同一个客户端发起的事务请求，最终将会严格按照其发起顺序被应用到ZooKeeper中 原子性 所有事务请求的结果在集群中所有机器上的应用情况是一致的，也就是说要么整个集群所有集群都成功应用了某一个事务，要么都没有应用，一定不会出现集群中部分机器应用了该事务，而另外一部分没有应用的情况 单一视图 无论客户端连接的是哪个ZooKeeper服务器，其看到的服务端数据模型都是一致的 可靠性 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更 实时性 通常人们看到实时性的第一反应是，一旦一个事务被成功应用，那么客户端能够立即从服务端上读取到这个事务变更后的最新数据状态。这里需要注意的是，ZooKeeper仅仅保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态，如果需要保证每次得到最新的状态，需要调sync接口保证. 工作原理基本状态 四种状态 LOOKING : 当前Server不知道leader是谁，正在搜寻 LEADING : 当前Server即为选举出来的leader OBSERVING : 观察着，与Follower功能类似，但不参与选举 FOLLOWING : leader已经选举出来，当前Server与之同步 注意LOOKING只在集群刚启动时没有Leader时会出现，一般不出现。在一般的情况下只有三种角色：Leader，Follower，Observer。一个zk集群同一时刻只会有一个Leader。zk默认为只有Leader，Follower角色，如果需要使用Observer角色，需要在任何想采用Observer的节点的配置文件加上peerType=observer,并同时在所有的server的配置文件中配置类似server.1:localhost:2888:3888:observer这种模式。Leader的机器是通过Leader选举的过程选举出来，该Leader服务器为客户端提供着读写服务。Follower和Observer都能提供读服务，但是不提供写服务。Observer不参与Leader的选举过程，也不参与写操作(过半写成功)的策略，因此这个可以在不影响写性能的情况下提升集群的读性能 zk文件系统特性每个子目录项如 NameService都被称作为znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 znode类型 PERSISTENT 持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL 持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL 临时目录节点 客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL 临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 分布式协调ZooKeeper中特有Watcher注册与异步通知机制，能够很好的实现分布式环境下不同机器，甚至不同系统之间的通知与协调，从而实现对数据变更的实时处理。使用方法通常是不同的客户端都对ZK上同一个ZNode进行注册，监听ZNode的变化（包括ZNode本身内容及子节点的），如果ZNode发生了变化，那么所有订阅的客户端都能够接收到相应的Watcher通知，并做出相应的处理 集群架构架构组成zk集群由多个节点组成，其中有且仅有一个leader，处理所有事务请求；follower及observer统称learner。learner需要同步leader的数据。follower还参与选举及事务决策过程。zk客户端会打散配置文件中的serverAddress 顺序并随机组成新的list，然后循环按序取一个服务器地址进行连接，直到成功。follower及observer会将事务请求转交给leader处理。 集群规模要搭建一个高可用的zk集群，我们首先需要确定好集群规模。一般我们将节点（指leader及follower节点，不包括observer节点）个数设置为 2*n+1 ，n为可容忍宕机的个数。 zk使用“过半”设计原则，很好地解决了单点问题，提升了集群容灾能力。但是zk的集群伸缩不是很灵活，集群中所有机器ip及port都是事先配置在每个服务的zoo.cfg文件里的。如果要往集群增加一个follower节点，首先需要更改所有机器的zoo.cfg，然后逐个重启。 集群工作流程 加载配置文件zoo.cfg 初始化核心类 加载本地快照以及事务日志，恢复内存数据 选举leader 数据同步，leader与learner之间同步 过半原则完成数据同步ACK(当leader收到过半的learner完成数据同步的ACK，集群开始正常工作) ZAB协议概览 ZooKeeper是Chubby的开源实现，而Chubby是Paxos的工程实现，所以很多人以为ZooKeeper也是Paxos算法的工程实现。事实上，ZooKeeper并没有完全采用Paxos算法，而是使用了一种称为ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法 算法要点 ZooKeeper使用了一个单一的主进程（Leader）来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程上去（Follower）。ZAB协议的这个主备模型架构保证了同一时刻集群中只能有一个主进程来广播服务器的状态变更，因此能够很好地处理客户端大量的并发请求。另一方面，考虑到分布式环境中，顺序执行的一些状态变更其前后会存在一定的依赖关系，有些状态变更必须依赖于比它早生成的那些状态变更，例如变更C需要依赖变更A和变更B。这样的依赖关系也对ZAB协议提出了一个要求：ZAB协议必须能够保证一个全局的变更序列被顺序应用。也就是说，ZAB协议需要保证如果一个状态变更已经被处理了，那么所有依赖的状态变更都应该已经被提前处理掉了。最后，考虑到主进程在任何时候都有可能出现崩溃退出或重启现象，因此，ZAB协议还需要做到在当前主进程出现上述异常情况的时候，依然能够正常工作. 核心 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为Follower服务器。Leader服务器负责将一个客户端事务请求转换成一个事务Proposal（提案）并将该Proposal分发给集群中所有的Follower服务器。之后Leader服务器需要等待所有Follower服务器的反馈，一旦超过半数的Follower服务器进行了正确的反馈后，Leader就会再次向所有的Follower服务器分发Commit消息，要求对刚才的Proposal进行提交 具体内容两种基本模式 崩溃恢复 在整个ZooKeeper集群启动过程中，或是当Leader服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的Leader服务器，同时集群中有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式.状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致. 消息广播 ZAB协议的消息广播过程使用原子广播协议，类似于一个二阶段提交过程，针对客户端的事务请求，Leader服务器会为其生成对应的事务Proposal，并将其发送给集群中其余所有的机器，然后再分别收集各自的选票，最后进行事务提交。集群中过半的Follower服务器完成了和Leader服务器的状态同步，整个集群就可以进入消息广播。 消息广播具体实现 在消息广播过程中，Leader服务器会为每一个Follower服务器都各自分配一个单独的队列，然后将需要广播的事务Proposal依次放入这些队列中去，并且根据FIFO策略进行消息发送。每一个Follower服务器在接收到这个事务Proposal之后，都会首先将其以事务日志的形式写入到本地磁盘中去，并且在成功写入后反馈给Leader服务器一个Ack响应。当Leader服务器接收到超过半数Follower的Ack响应后，就会广播一个Commit消息给所有的Follower服务器以通知其进行事务提交，同时Leader自身也会完成对事务的提交，而每一个Follower服务器在接收到Commit消息后，也会完成对事务的提交. 基本特性 ZAB协议规定了如果一个事务Proposal在一台机器上被处理成功，那么应该在所有的机器上都被处理成功，哪怕机器出现故障崩溃。ZAB协议需要确保那些已经在Leader服务器上提交的事务最终被所有服务器都提交，假设一个事务在Leader服务器上被提交了，并且已经得到了过半Follower服务器的Ack反馈，但是在它Commit消息发送给所有Follower机器之前，Leader服务挂了.ZAB协议需要确保丢弃那些只在Leader服务器上被提出的事务.因此Leader选举算法中必须能够确保提交已经被Leader提交的事务的Proposal，同时丢弃已经被跳过的事务Proposal。如果让Leader选举算法能够保证新选举出来的Leader服务器拥有集群中所有机器最高编号（ZXID最大）的事务Proposal，那么就可以保证这个新选举出来的Leader一定具有所有已经提交的提议，更为重要的是如果让具有最高编号事务的Proposal机器称为Leader，就可以省去Leader服务器查询Proposal的提交和丢弃工作这一步骤了。 Leader选举过程发生时机 服务器初始化启动 服务器运行期间无法与leader保持连接 投票依据信息 id集群中每个zk节点启动前配置的全局唯一的id，记录在myid中 zxid被推举的leader的事务id，此id越大表示事务状态越新。 执行过程 第一步设置状态为LOOKING，初始化内部投票（id，zxid）到内存中，并将其广播到集群的其他节点。首次投票选举自己为leader，然后将自身的id，处理的最近一个事务请求zxid以及当然状态广播出去。最后进入循环等待和处理其他节点的投票信息的流程中。 第二步循环等待，节点每收到一个外部的Vote信息，需要将其与自己内存中Vote数据进行PK，规则为取ZXID最大，如果ZXID相等，则去ID大的那个投票。如果外部投票获胜，节点需要将选票覆盖之前的内存Vote数据，同时再广播出去。同时还需要统计是否有过半的赞同者与新的内存投票数据一致，无则需要继续等待新的投票，有则需要判断leader是否在赞同者之中，在则退出循环，选举结束，根据选举结果以及各自角色切换状态。 选举完成后数据同步概述 选主算法中的zxid是从内存数据库中取的最新事务id，事务操作是分两阶段的（提出阶段和提交阶段），leader生成提议并广播给followers，收到半数以上的ACK后，再广播commit消息，同时将事务操作应用到内存中。follower收到提议后先将事务写到本地事务日志，然后反馈ACK，等接到leader的commit消息时，才会将事务操作应用到内存中。可见，选主只是选出了内存数据是最新的节点，仅仅靠这个是无法保证已经在leader服务器上提交的事务最终被所有服务器都提交. 具体流程 加载快照 重新加载本地磁盘上的数据快照至内存，并从日志文件中取出快照之后的所有事务操作，逐条应用至内存，并添加到已提交事务缓存commitedProposals。这样能保证日志文件中的事务操作，必定会应用到leader的内存数据库中 事务同步 获取learner发送的FOLLOWERINFO/OBSERVERINFO信息，并与自身commitedProposals比对，确定采用哪种同步方式，不同的learner可能采用不同同步方式（DIFF同步、TRUNC+DIFF同步、SNAP同步）。这里是拿learner内存中的zxid与leader内存中的commitedProposals（min、max）比对，如果zxid介于min与max之间，但又不存在于commitedProposals中时，说明该zxid对应的事务需要TRUNC回滚；如果zxid介于min与max之间且存在于commitedProposals中，则leader需要将zxid+1~max间所有事务同步给learner，这些内存缺失数据，很可能是因为leader切换过程中造成commit消息丢失，learner只完成了事务日志写入，未完成提交事务，未应用到内存. 数据同步 leader主动向所有learner发送同步数据消息，每个learner有自己的发送队列，互不干扰。同步结束时，leader会向learner发送NEWLEADER指令，同时learner会反馈一个ACK。当leader接收到来自learner的ACK消息后，就认为当前learner已经完成了数据同步，同时进入“过半策略”等待阶段。当leader统计到收到了一半已上的ACK时，会向所有已经完成数据同步的learner发送一个UPTODATE指令，用来通知learner集群已经完成了数据同步，可以对外服务了 实际应用Zookeeper配置管理 leader主动向所有learner发送同步数据消息，每个learner有自己的发送队列，互不干扰。同步结束时，leader会向learner发送NEWLEADER指令，同时learner会反馈一个ACK。当leader接收到来自learner的ACK消息后，就认为当前learner已经完成了数据同步，同时进入“过半策略”等待阶段。当leader统计到收到了一半已上的ACK时，会向所有已经完成数据同步的learner发送一个UPTODATE指令，用来通知learner集群已经完成了数据同步，可以对外服务了 Zookeeper 集群管理 这个是用场景就更加广泛了，Hadoop中的master选举就是采用zookeeper。集群管理一般涉及到2点，机器的加入和退出，选举master。 对于机器的加入和退出，所有机器约定在Groupmembers创建一个临时目录节点。然后可以监听父目录节点的子节点的变化消息，一旦有机器宕机，此机器与zookeeper的连接会断开，其创建的临时目录节点会被删除。对于新机器加入，会建立与zookeeper的连接，然后回在groupmembers创建一个临时目录节点，同时所有机器都会被通知有新机器加入。 对于选举master，一种简单的方式就是所有机器创建临时顺序编号目录节点，这样所有机器对应就是编号关系，我们可以每次选取最小的机器作为master即可 Zookeeper 分布式锁 通过对Zookeeper的原理进行分析，我们可以知道Zookeeper具有一致性文件系统的特性，可以利用这个特点实现分布式锁。我们创建两种类型的分布式锁，一种为保持独占的锁，另一种是控制时序的锁。保持独占的锁，可以通过Zookeeper创建节点的特性来实现。我们可以将zookeeper文件系统的每一个节点目录作为一把锁。所有的机器会去创建/distribute_lock节点，根据zookeeper的特性，只有一个机器会创建成功，这个成功创建的那个客户端也就获得这把锁。使用完成后只需删除这一临时目录节点即可。 第二类针对的是/distribute_lock已经存在。所有客户端会在它下面创建临时顺序编号目录节点，我们可以指定编号最小的获得锁，用完即删除临时节点","tags":[{"name":"Java","slug":"Java","permalink":"http://yqyao.github.io/tags/Java/"}]},{"title":"mysql","date":"2017-03-21T15:10:38.000Z","path":"2017/03/21/mysql/","text":"Centos 7 yum 安装mysql 踩坑日记安装方法1yum -y instatll *mysqld* 不能简单的yum install mysql 否则会有很多依赖没有安装 问题然后service mysqld status 发现出现错误查看日志 tail /var/log/mysqld.log2017-03-21 21:45:16 6796 [ERROR] Fatal error: Can’t open and lock privilege tables: Table ‘mysql.user’ doesn’t exist 解决方法查看 /etc/my.conf 并修改部分代码 123456789[mysqld]#datadir=/var/lib/mysql # 没修改之前datadir=/opt/datasocket=/var/lib/mysql/mysql.sockuser=mysql #原始状态没有这两条old_passwords=1 #[mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 重新启动1service mysqld start Mysql 基本语句学习cmd命令行语句学习 登陆1mysql -u root -p # 输入密码即可，以root用户登录 -u表示username，即用户名。-p表示password，即密码 创建数据库 1create database 库名 选择数据库 1use 库名 查看数据库 1show databases; 删除数据库 1drop database 库名 创建用户 1CREATE USER 'username'@'host' IDENTIFIED BY 'password'; 数据库授权 123格式：grant select on 数据库.* to 用户名@登录主机 identified by \"密码\"grant select,insert,update,delete on *.* to yyq@\"%\" Identified by \"123456\";#增加一个用户yyq密码为123456，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限,需要以root用户登录mysql，然后输入此命令 查看表格1show tables; 数据定义语言（DDL） 创建删除数据库 12CREATE DATABASE TESTDB;DROP DATABASE TESTDB; 创建表 123456CREATE TABLE student ( id int primary key auto_increment, gender char(1), age int(2), birth date ); 定义字段的格式：字段的名字+字段的类型+属性 查看表结构 1desc student 删除表 1drop table student 修改表结构 alter table student add column score int(2); –添加表列 alter table student rename student2; –修改表名 alter table student drop column score; –删除表列 alter table student modify age char(2) –修改表列类型（改类型） alter table student change column score score1 float(4)–修改表列名（改名字和类型） 数据操纵语言 添加数据insert into tablename (col1, clo2, clo3) values(value1, value2, value3); 1insert into student (id, gender, age, birth) values(1, 'm', 23, \"1999-2-3\") 查询数据 12select * from studentselect score from student 修改数据（UPDATE … SET语句）： 1update student set age=25, score=78 where id = 1; 删除数据：（DELETE FROM…语句） 12delete from student # 删除所有记录delete from student where id = 1 # 删除符合条件的数据 数据查询语句实际开发中select 语句可能用的最多，使用的场景也非常广泛123456select score from student where id = 1;select score, age student where id = 1;select score from student where gender = m;select id from student where score &gt; 60;select id from student order by score; 升序select id from student order by score desc; 降序 事务控制语言（TCL）1、事务： 事务(Transaction)的概念：事务(Transaction)是访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。在关系数据库中，一个事务可以是一条SQL语句，一组SQL语句或整个程序。 事务的属性：原子性（atomicity）、一致性（consistency）、隔离性（isolation）、持续性（durability）。这四个属性通常称为ACID特性。 事务的特点：事务就是对数据库的多步操作，要么一起成功，要么一起失败。 总结：事务就是可以把多步操作看成一个整体，这个整体要么一起成功，要么一起失败。 2、事务的提交和回滚命令： 设置默认事务提交方式：（默认为true） 设置事务提交方式为“手动提交”： 1set autocommit = false; 设置事务提交方式为“自动提交”： 1set autocommit = true; 特殊语法a表 id name num 1 张3 1 2 李四 2 3 王五 3 b表 age parnet_id 23 1 34 2 34 3 内连接1select a.*,b.* from a inner join b on a.id=b.parent_id 1 张3 1 23 1 2 李四 2 34 2 2017-04-03 20:12:12 星期一 左连接 1select a.*,b.* from a left join b on a.id=b.parent_id 1 张3 1 23 1 2 李四 2 34 2 3 王五 3 右连接1select a.*,b.* from a right join b on a.id=b.parent_id 1 张3 1 23 1 2 李四 2 34 2 null null 3 34 4 完全连接1select a.*,b.* from a full join b on a.id=b.parent_id 1 张3 1 23 1 2 李四 2 34 2 null null 3 34 4 3 王五 null null python使用Mysql首先需要安装MySQL-python去官网下载然后解压安装即可，貌似只有python2有，python3没有，但是python3有另一种PyMySQL使用方法同MySQL-python基本一致另一种安装方式1pip install MySQL-python 代码实例12345678910111213141516171819202122232425262728293031323334353637383940414243import MySQLdb as mdbimport pickleimport structconfig = &#123; 'host': '127.0.0.1', 'port': 3306, 'user': 'root', 'passwd': '12345', 'db': 'mytest', 'charset': 'utf8'&#125;conn = mdb.connect(**config)''' 如果使用事务引擎，可以设置自动提交事务，或者在每次操作完成后手动提交事务conn.commit()'''conn.autocommit(1) # conn.autocommit(True) #使用cursor()方法获取操作游标cursor = conn.cursor()#因该模块底层其实是调用CAPI的，所以，需要先得到当前指向数据库的指针#创建数据表cursor.execute(\"create table student(id int ,name varchar(20),class varchar(30),age varchar(10))\")#插入一条数据cursor.execute(\"insert into student values('2','Tom','3 year 2 class','9')\")#另一种方式sqli = \"insert into student values(%s,%s,%s,%s)\"cursor.execute(sqli,('3','Huhu','2 year 1 class','7'))#一次插入多条记录sqli = \"insert into student values(%s,%s,%s,%s)\"cursor.executemany(sqli,[ ('3','Tom','1 year 1 class','6'), ('3','Jack','2 year 1 class','7'), ('3','Yaheng','2 year 2 class','7'), ])#更新查询条件的数据cursor.execute(\"update student set class='3 year 1 class' where name = 'Tom'\")#删除查询条件的数据cursor.execute(\"delete from student where age='9'\")#获取数据count = cursor.execute(\"select * from student\") # count 为返回结果的数目cursor.fetchone() #获取一条数据cursor.fetchmany(count) # 获取多条数据#关闭游标和数据库连接cursor.close()conn.close()","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yqyao.github.io/tags/mysql/"}]},{"title":"python_class","date":"2017-03-21T12:29:23.000Z","path":"2017/03/21/python-class/","text":"特殊方法定制类python中的容器如list，dict，set理论上都是线程不安全的。在一般的情况下由于GIL的存在，我们很少会考虑到线程安全的问题，但是对于多线程来说，可能会出现意想不到的事情。在某次项目中，我使用了字典作为一个缓冲区，需要不断的删改，这就导致了多线程调用时异常。因此一个线程安全的缓冲区就十分有必要了。 由于我们需要的仅仅只是一个缓冲区，我们可以自己定制一个线程安全的类。借助threading 中的Lock模块来实现线程安全。 定制特定类对于python类， 有很多内置的方法可以使用比如。我们常见的比如构造方法init(self),析构方法del(self),除了这个我们还有其他的方法。 模拟字典1234567__hash__(self) # hash 函数值__len__(self) # mapping 中项的数目__getitem__(self, key) # 得到给定key的值__setitem__(self, key, val) # 设定给定键的值__delitem__(self, key) # 删除给定键__iter__(self) # 创建迭代类__contains__(self, key) # 判断key是否在字典中 实际使用方法可以和字典一样，直接用[]符号访问即可 序列类型dict 123456789__len__(self) # 得到序列长度__getitem__(self, key)# 得到单个序列元素__setitem__(self, key, val) # 设定某个序列的元素值__delitem__(self, key) # 删除单个序列元素__getslice__(self, ind1, ind2) # 得到序列片段__setslice__(self, ind, val) # 设置序列片段__delslice__(self, ind1, ind2) # 删除序列片段__iter__(self) # 创建迭代类__add__(self, obj) # 串联操作 实际操作方法和list一样。 代码实例list12345678910111213141516171819202122232425262728293031323334353637383940414243class Safe_list: def __init__(self): self.list = list() self.lock = Lock() def __getitem__(self, ind): with self.lock: return self.list[ind] def __str__(self): with self.lock: return str(self.list) def __setitem__(self, ind, value): with self.lock: self.list[ind] = value def __len__(self): with self.lock: return len(self.list) def __contains__(self, key): with self.lock: return key in self.list def __delitem__(self, ind): with self.lock: del self.list[ind] def __getslice__(self, ind1, ind2): with self.lock: return self.list[ind1: ind2] def __setslice__(self, ind1, ind2, val): with self.lock: self.list[ind1:ind2] = val def __add__(self, obj): with self.lock: return self.list + obj.list def __reversed__(self): with self.lock: return reversed(self.list) def enumerate(self): with self.lock: return idx, value in enumerate(self.list) def append(self, value): with self.lock: self.list.append(value) def extend(self, value): with self.lock: return self.list.extend(value) dict123456789101112131415161718192021class My_dict: def __init__(self): self.dict = dict() def __del__(self): print \"do something\" def __getitem__(self, key): return self.dict[key] def __len__(self): return len(self.dict) def __contains__(self, key): return key in self.dict def __setitem__(self, key, val): self.dict[key] = val def __delitem__(self, key): del self.dict[key] &gt;&gt;&gt; mydict = My_dict() &gt;&gt;&gt; mydict['key1'] = 3 &gt;&gt;&gt; mydict['key1']3 顺序字典 介绍OrderedDict是dict的子类，它记住了内容添加的顺序，对于缓冲区这是很好的性质我们可以设置缓冲区最老的变量在达到缓冲区最大长度是被删除。 特殊方法OrderedDict.popitem(last=Truelast为True是LIFO,即为堆栈，反之是FIFO，即为队列),甚至这个还支持排序 reversed() 实例 12345678910111213from collections import OrderedDict d = OrderedDict()d.popitem(last=False) # 队列模式FIFO d['key1'] = 1d['key2'] = 2d['key3'] = 3d['key4'] = 4&gt;&gt;&gt; for k, v in d.items(): print v1234 线程锁我们以3个线程为例 123456789101112131415161718192021import time import threading num = 0 class MyThread(threading.Thread): def run(self): #lock.acquire() with lock: global num num += 1 print self.name + 'set num to '+str(num) #lock.release()lock = threading.RLock() # 这个是锁里还可以获得锁，Lock()是普通锁threads = [] for i in range(10000): t = MyThread() threads.append(t) for i in range(10000): threads[i].start() for i in range(10000): threads[i].join() 对于lock.acquire()和lock.release(),我们可以用with表达式简化书写，实际上都是一样的 线程安全的缓冲区 实现代码通过OrderDict 以及threading 的加锁模块我们定制一个线程安全的缓冲区 12345678910111213141516171819202122232425262728293031from collections import OrderedDict from threading import Lock class Cache: def __init__(self,size=100): if int(size)&lt;1 : raise AttributeError('size &lt; 1 or not a number') self.size = size self.dict = OrderedDict() self.lock = Lock() def __getitem__(self,key): with self.lock: return self.dict[key] def __setitem__(self,key,value): with self.lock: while len(self.dict) &gt;= self.size: self.dict.popitem(last=False) self.dict[key]=value def __len__(self): with self.lock: return len(self.dict) def __contains__(self, key): with self.lock: return key in self.dict def __iter__(self): with self.lock: return self.dict.itervalues() def __delitem__(self,key): with self.lock: del self.dict[key] 使用方法 123456789101112cache = Cache(size = 3)cache['key1'] = \"val1\"cache['key2'] = \"val2\"cache['key3'] = \"val3\"cache['key4'] = \"val4\"for k in cache: print koutput:val2val3val4","tags":[{"name":"python","slug":"python","permalink":"http://yqyao.github.io/tags/python/"}]},{"title":"python multiprocessing","date":"2017-03-21T12:29:23.000Z","path":"2017/03/21/multiprocess/","text":"python多线程学习multiprocessing这个是python 标准库中自带的，用起来也很方便12from multiprocessing.dummy import Pool # 这个是多线程from multiprocessing import Pool # 这个是多进程 用法实例12345678910from multiprocessing.dummy import Pool as ThreadPool # 这个是多线程path_list = list()for i in xrange(10): path_list.append(i)def test(path): print pathpool = ThreadPool(processes=1)pool.map(test, path_list)pool.close()pool.join() futures backgroundPython标准库为我们提供了threading和multiprocessing模块编写相应的多线程/多进程代码，但是当项目达到一定的规模，频繁创建/销毁进程或者线程是非常消耗资源的，这个时候我们就要编写自己的线程池/进程池，以空间换时间。但从Python3.2开始，标准库为我们提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，实现了对threading和multiprocessing的进一步抽象，对编写线程池/进程池提供了直接的支持。 futures 123456789101112import timefrom concurrent.futures import ProcessPoolExecutor, as_completedNUMBERS = range(25, 38)def fib(n): if n&lt;= 2: return 1 return fib(n-1) + fib(n-2)start = time.time()with ProcessPoolExecutor(max_workers=3) as executor: for num, result in zip(NUMBERS, executor.map(fib, NUMBERS)): print 'fib(&#123;&#125;) = &#123;&#125;'.format(num, result)print 'COST: &#123;&#125;'.format(time.time() - start) multiprocessing 12345678910111213import timefrom multiprocessing.pool import PoolNUMBERS = range(25, 38)def fib(n): if n&lt;= 2: return 1 return fib(n-1) + fib(n-2)start = time.time()pool = Pool(3)results = pool.map(fib, NUMBERS)for num, result in zip(NUMBERS, pool.map(fib, NUMBERS)): print 'fib(&#123;&#125;) = &#123;&#125;'.format(num, result)print 'COST: &#123;&#125;'.format(time.time() - start) 设计模式 Future是常见的一种并发设计模式，在多个其他语言中都可以见到这种解决方案一个Future对象代表了一些尚未就绪（完成）的结果，在「将来」的某个时间就绪了之后就可以获取到这个结果。比如上面的例子，我们期望并发的执行一些参数不同的fib函数，获取全部的结果。传统模式就是在等待queue.get返回结果，这个是同步模式，而在Future模式下， 调用方式改为异步，而原先等待返回的时间段，由于「Local worker thread」的存在，这个时候可以完成其他工作 futures 中的submit 和map区别submit 1234567891011121314from concurrent import futuresimport timepath_list = list()import mathfor i in xrange(3): path_list.append(\"\".join(\"path\"+str(i)))pool = futures.ThreadPoolExecutor(3)def test(path): print \"poth\" pool.submit(test, path_list)#result:#['path0', 'path1', 'path2'] map 12345678910111213141516from concurrent import futuresimport timepath_list = list()import mathfor i in xrange(3): path_list.append(\"\".join(\"path\"+str(i)))pool = futures.ThreadPoolExecutor(3)def test(path): print \"poth\" pool.map(test, path_list)#result:#path0#path1#path2 可以根据需求来选择使用submit还是map，如果请求类型都相同可以选择用map","tags":[{"name":"python","slug":"python","permalink":"http://yqyao.github.io/tags/python/"}]},{"title":"dlfcn","date":"2017-03-11T14:53:06.000Z","path":"2017/03/11/dlfcn/","text":"Cython 如何调用动态链接库总结最近因为工程需要，在编写cython的过程中需要调用动态链接库，需要用到dlfcn.h这个底层头文件，在实际操作中发现Cython竟然没有这个头文件。在查阅Cython的源码才得知其确实没有这个头文件，不过在查阅资料后发现这个头文件非常简单，可以手动去往Cyhton中的源码中去加，然后重新编译即可。本文是最近一段时间的关于这一方面的总结，以后再遇到这个问题可以及时查阅。 C中加载动态链接库的方法生产动态链接库编译参数 gcc -fPIC -share123456789101112int add(int a, int b) &#123;return (a + b);&#125;int sub(int a, int b) &#123;return (a - b);&#125;int mul(int a, int b) &#123;return (a * b);&#125;int div(int a, int b) &#123;return (a / b);&#125; 编译如下： gcc -fPIC -shared test.c -o libtest.so dlfcn.h 函数说明1234int dlclose(void *handle)char *dlerror(void)void *dlopen(const char *filename, int flag)void *dlsym(void *handle, const char *symbol) 说明dlopen以指定模式打开指定的动态连接库文件，并返回一个句柄给调用进程，dlerror返回出现的错误，dlsym通过句柄和连接符名称获取函数名或者变量名，dlclose来卸载打开的库。 dlopen打开模式如下RTLD_LAZY 暂缓决定，等有需要时再解出符号RTLD_NOW 立即决定，返回前解除所有未决定的符号 测试代码1234567891011121314151617181920212223242526272829303132333435363738#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;dlfcn.h&gt;//动态库路径#define LIB_TEST_LIB = \"./libtest.so\"//定义函数类型指针typedef int(*TEST_TYPE)(int, int);//主函数int main() &#123; void *handle; char* error; TEST_TYPE test_type; //打开动态链接库 dl_handle = dlopen(LIB_TEST_LIB, RTLD_LAZY); // 检查是否打开正常 if(!handle) &#123; fprintf(stderr, \"%s\\n\", dlerror()); exit(EXIT_FAILURE); &#125; // 清除错误 dlerror(); //获取函数 test_type = (TEST_TYPE)dlsym(handle, \"add\"); //检查是否错误 if ((error =dlerror()) != NULL) &#123; fprintf(stderr, \"%s\\n\", error); exit(EXIT_FAILURE); &#125; printf(\"add: %d\\n\", test_type(2, 9)); //输出11 test_type = (TEST_TYPE)dlsym(handle, \"mul\"); printf(\"mul: %d\\n\", test_type(2, 9)); // 输出18 //关闭handle dlclose(handle); exit(EXIT_SUCCESS);&#125; 编译选项为：gcc -rdynamic -o main main.c -ldl需要注意typedef int (FUNC)(int ,int )是定义一个函数类型指针，int func(int ,int )，是返回一个int指针，两者不同。前者是一种指向函数类型int (int,int)的指针， 后者返回的是一个int 类型的指针个人理解是这样的：12345678FUNC test;int add(int a, int b) &#123; return a + b;&#125;test = add;int out = test(1, 2);printf(\"%d\\n\", out);//输出结果为3 再谈如何在Cython中调用之前我们安装Cython的时候一般都是通过pip install cython 来安装的，这种情况下是用不了dlfcn.h这个头文件的，因为官方没有将这个头文件写成cython能够识别的格式即pxd的格式，因此我们需要先写一个dlfcn.pxd的文件，放入到Cython中的源码中，然后使用Cython的源码安装，这样才能使用。 dlfcn.pxd 12345678910cdef extern from \"&lt;dlfcn.h&gt;\" nogil: int RTLD_LAZY int RTLD_NOW int RTLD_GLOBAL int RTLD_LOCAL int dlclose(void *) char *dlerror(void) void *dlopen(const char *, int) void *dlsym(void *restrict, const char *restrict) 内容很简单，加入到./cython/Cython/Include/libc 这个文件夹即可。如果不想加，这个是我加好的Cython 你可以git clone 下来即可。 编译Cyhton 1python setup.py install 编写test.pyx 123456789101112from libc.dlfcn cimport*cimport cythoncdef void* dl_handledef get_dl_handle(): global dl_handle dl_handle = dlopen(\"./libtest.so\", RTLD_LAZY)def test_dlfcn(): cdef: int test_add = &lt;int&gt;dlsym(dl_handle, \"add\") temp = test_add(1, 2) print temp 编译生成的test.pyx,测试生成的库为test.so 123import testtest.test_dlfcn()# 输出为 3 注意也可用生成函数类型指针去测试，这里为了简单直接使用这种简单的方式去测试。","tags":[{"name":"cython","slug":"cython","permalink":"http://yqyao.github.io/tags/cython/"}]},{"title":"Git 使用笔记","date":"2017-03-03T14:13:03.000Z","path":"2017/03/03/git/","text":"Git 初步使用 初始化 1git init 添加文件到仓库 123git add &lt;file&gt;git add . (增加所有的文件到仓库)git commit -m \" descriptions\" 查看状态和查看修改内容 12git statusgit diff 版本回退 1234git log --pretty=oneline 显示提交日志，完整版本号git reflog 查看命令历史git reset --hard HEAD^ 回到上一版本git reset --hard cb926e7e 回到某一个版本 撤销修改 12git checkout -- file # 修改了文件，但是没有addgit reset HEAD file &amp;&amp; git checkout -- file # 修改了文件而且add file 删除文件 123rm file # 工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了git rm file &amp;&amp; git commit 将版本库中file 删除git checkout -- file 对于误删文件可以用这条命令恢复，但是只能恢复最新版本 远程仓库 添加远程仓库 1git remote add origin git@github.com:michaelliao/learngit.git 推送到远程仓库 12git push -u origin master 第一次推送git push origin master 后续推送 克隆 仓库 1git clone git@github.com:michaelliao/learngit.git 分支管理 创建和查看分支 12git branch &lt;name&gt; 创建分支git brabch 查看分支 切换分支 12git checkout &lt;name&gt; 切换分支git checkout -b &lt;name&gt; 创建并切换分支 合并和删除分支 12git merge &lt;name&gt; 合并某分支到当前分支git branch -d &lt;name&gt; 删除分支 其他配置 配置别名 1234git config --global alias.st status # st = statusgit config --global alias.co checkout # co checkoutgit config --global alias.ci commit # ci commitgit config --global alias.br branch #br branch Git 配置文件修改 12[alias]co = checkout 忽略特殊文件12345*.pyc*.so*.log*.pidtest/*","tags":[{"name":"Git","slug":"Git","permalink":"http://yqyao.github.io/tags/Git/"}]},{"title":"cython_FILE","date":"2017-02-13T06:31:35.000Z","path":"2017/02/13/cython-FILE/","text":"cython FIlE 用法C中FILE的用法 定义文件指针变量 1FILE *fp; 打开操作的文件 12345678fp = fopen('test.txt','r'); //只读fp = fopen('test.txt','rb'); //以二进制形式，只读fp = fopen('test.txt','w'); //只写fp = fopen('test.txt','wb'); //以二进制形式，只写fp = fopen('test.txt','r+'); // 可读可写，指针指向文件头fp = fopen('test.txt','rb+'); //以二进制形式fp = fopen('test.txt','a+'); //可读可写，文件指针指向文件尾，即追加模式添加fp = fopen('test.txt','ab+'); //以二进制形式 设置文件读写指针位置 12345678//将文件读/写指针移到距文件头100字节处 fseek( fp, 100L, SEEK_SET );//将文件读/写指针从当前位置向文件尾方向移50字节 fseek( fp, 50L, SEEK_CUR ); //将文件读/写指针从当前位置向文件头方向移50字节 fseek( fp, -50L, SEEK_CUR ); //将文件读/写指针从文件尾回移100字节 fseek( fp, -100L, SEEK_END ); 对文件进行读写操作 格式：字节变量=fgetc( FILE *fp ); fp 这是个文件指针，它指出要从中读取字符的文件 实例12//从文件中读取1个字节给ch ch =fgetc( fp ); 格式：fputc( char str, FILE fp ); str：指出要写到文件中去的字符串。 fp：这是个文件指针，指出字符串要写入其中的文件。 实例12//将ch(单字节)值写入文件 fputc( ch, fp ); 格式：fputs/fgets(char str, int n, FILE fp ); str：接收字符串的内存地址，可以是数组名，也可以是指针。 n： 指出要读取字符的个数。 fp：这是个文件指针，指出要从中读取字符的文件 实例1234//从文件中读取字符串(5个字符)给str fgets( str, 5, fp ); //将str字符串写入文件 fputs( str, fp ); 格式：fread/fwrite(void buffer, unsigned size, unsigned count, FILE fp ); buffer：这是一个void型指针，指出要将读入h或写入数据存放在其中的存储区首地址。 size：指出一个数据块的字节数，即一个数据块的大小尺寸。 count：指出一次读入多少个数据块（sife）。 fp：这是个文件指针，指出要从其中读出数据的文件。 实例12345int var[5];//从文件中读取5个指定字节长度数据给指定类型变量数组var fread( var, sizeof(var[0]), 5, fp ); //将指定类型变量数组var的前5个元素写入文件 fwrite( var, sizeof(var[0]), 5, fp ); 其他函数 fprintf() 和fscanf() 1234//用法同printffprintf(fp,\"%2d%s\",4,\"Hahaha\")// 从流中按格式读取fscanf(fp,\"%d%d\" ,&amp;x,&amp;y) feof() 和 ferror() 1234// 判断是否到文件尾if(feof(fp))printf(\"已到文件尾\");//返回流最近的错误代码printf(\"%d\",ferror(fp)); rewind() 和remove() 1234//把当前的读写位置回到文件开始rewind(fp); // 删除文件remove(\"test.txt\"); 简单的一个实例lib_c 这个文件前4个字节表示length，后面存储的是一个二维数组，维度为length*128，存储的是浮点数123456789101112131415161718192021#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main()&#123; FILE *fp; int length; char *file_path; int file_size; float *array; file_path = \"lib_c\"; fp = fopen(file_path, \"rb\"); fread(&amp;length, sizeof(int), 1, fp); printf(\"%d\\n\", length); file_size = length*128; array = (float*)malloc(sizeof(float)*file_size); fread(array, 4, file_size, fp); printf(\"%f\\n\", array[0]); fclose(fp); free(array); return 0;&#125; cython 中使用12345678910111213141516from libc.stdib cimport*from libc.stdio cimport*def test(): cdef: FILE *p int length float *array str file_path file_path = 'lib_c' fp = fopen(file_path, \"rb\"); fread(&amp;length, sizeof(int), 1, fp); file_size = length*128; array = &lt;float*&gt;malloc(sizeof(float)*file_size); fread(array, 4, file_size, fp); fclose(fp); free(array); 这里就得到了一个c中的二维数组，如果调用底层c的模块需要传入c中的数组，这里可以这么使用","tags":[{"name":"cython","slug":"cython","permalink":"http://yqyao.github.io/tags/cython/"}]},{"title":"struct","date":"2017-02-13T05:07:26.000Z","path":"2017/02/13/struct/","text":"Python struct 用法主要函数 pack(fmt, v1, v2, …)根据所给的fmt描述的格式将值v1，v2，…转换为一个字符串 unpack(fmt, bytes)根据所给的fmt描述的格式将bytes反向解析出来，返回一个元组 calcsize(fmt)根据所给的fmt描述的格式返回该结构的大小 主要定义格式 i – int f – float d double s string 其他可看官方文档 实例 pack 12feature = [1.0,2.0,3.0]buf = struct.pack('%if' % len(feature), *feature) 加上文件 12345length = 3with open('test.txt','wb') as fw: string = '' string += struct.pack(\"i\", length) fw.write(string) unpack 123feature_lenght = 10 with open('test.txt', 'rb') as f: feature_tuple = struct.unpack('%if' %feature_length, f.read()) calcsize 1struct.calcsize('ii') #返回8 struct 处理结构体 需要处理的结构体 1234567struct header&#123;unsigned short usType;char[4] acTag;unsigned int uiVersion;unsigned int uiLength;&#125;; python 解析此struct 1str = struct.pack('B4sII', 0x04, 'aaaa', 0x01, 0x0e) unpack 此结构体 1type, tag, version, length = struct.unpack('B4sll', str) 常用序列化工具cPickle dump函数用法 (处理文件) 123test_list = ['a','b','c']with open('test.txt', 'wb') as f: cPickle.dump(test_list, f) load 函数用法(处理文件) 1234with open('test.txt', 'rb') as f： test_list = cPickle.load(f) print test_list&gt;&gt;&gt; ['a','b','c'] dumps 函数用法 12345test_list = ['a', 'b', 'c']obj = cPickle.dumps(test_list)print type(obj)&gt;&gt;&gt; &lt;type 'str'&gt;obj 以python专用的形式存储 loads 函数用法 123load_obj = cPickle.loads(obj)print load_obj&gt;&gt;&gt; ['a', 'b', 'c'] json 格式 dump函数用法 (处理文件) 123test_list = ['a','b','c']with open('test.txt', 'wb') as f: json.dump(test_list, f) load 函数用法(处理文件) 1234with open('test.txt', 'rb') as f： test_list = json.load(f) print test_list&gt;&gt;&gt; [u'a', u'b', u'c'] dumps 函数用法 12345test_list = ['a', 'b', 'c']obj = json.dumps(test_list)print type(obj)&gt;&gt;&gt; &lt;type 'str'&gt;obj 以python专用的形式存储 loads 函数用法 123load_obj = json.loads(obj)print load_obj&gt;&gt;&gt; [u'a', u'b', u'c']","tags":[{"name":"python","slug":"python","permalink":"http://yqyao.github.io/tags/python/"}]},{"title":"rsync","date":"2017-02-07T05:23:50.000Z","path":"2017/02/07/rsync/","text":"为何要用这个？ sersync是基于Inotify开发的，类似于Inotify-tools的工具 sersync可以记录下被监听目录中发生变化的（包括增加、删除、修改）具体某一个文件或某一个目录的名字，然后使用rsync同步的时候，只同步发生变化的这个文件或者这个目录。 rsync在同步的时候，只同步发生变化的这个文件或者这个目录（每次发生变化的数据相对整个同步目录数据来说是很小的，rsync在遍历查找比对文件时，速度很快），因此，效率很高。 测试机器 机器 ip10.0.2.123（内网地址）10.0.2.124 操作系统 centos7 两台机器既为客户端也为服务端 配置rsync 关闭SELINUX 123456vi /etc/selinux/config #编辑防火墙配置文件SELINUX=enforcing #注释掉SELINUXTYPE=targeted #注释掉SELINUX=disabled #增加:wq! #保存，退出setenforce 0 #立即生效 创建用户认证文件 设置本机用户名与密码 vi /etc/rsync.pas yyq:88888888 设置远程服务器的密码 vi /etc/rsync_server.pas 88888888 修改文件属性 chmod 600 /etc/rsync.pas chmod 600 /etc/rsync_server.pas 配置rsync一般的centos 系统会 自带rsync，但是没有配置文件，我们修改配置文件。vi /etc/rsyncd.conf #创建配置文件，添加以下代码log file = /var/log/rsyncd.log #日志文件位置，启动rsync后自动产生这个文件，无需提前创建pidfile = /var/run/rsyncd.pid #pid文件的存放位置lock file = /var/run/rsync.lock #支持max connections参数的锁文件secrets file = /etc/rsync.pass #用户认证配置文件，里面保存用户名称和密码，后面会创建这个文件uid = root #设置rsync运行权限为rootgid = root #设置rsync运行权限为rootuse chroot = no #默认为true，修改为no，增加对目录文件软连接的备份read only = no #设置rsync服务端文件为读写权限max connections = 200 #最大连接数timeout = 600 #设置超时时间[search] #自定义名称path = /home/yyq/ #rsync服务端数据目录路径auth users = yyqhosts allow = 10.0.2.123 #允许进行数据同步的客户端IP地址，可以设置多个，用英文状态下逗号隔开hosts deny = 10.0.2.125 # 禁止数据同步的客户端IP地址， 也可以设置多个 启动rsync rsync –daemon –config=/etc/rsyncd.conf 安装sersync 目的： 实时触发同步 下载sersync sersync 不需要编译，可直接使用其可执行文件。 sersync下载地址：https://sersync.googlecode.com/files/sersync2.5.4_64bit_binary_stable_final.tar.gz 配置 confxml.xml 12345678910111213141516171819202122&lt;sersync&gt; &lt;localpath watch=\"/opt/tongbu\"&gt; &lt;remote ip=\"10.0.2.123\" name=\"search\"/&gt; &lt;!--&lt;remote ip=\"192.168.8.39\" name=\"tongbu\"/&gt;--&gt; &lt;!--&lt;remote ip=\"192.168.8.40\" name=\"tongbu\"/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params=\"-artuz\"/&gt; &lt;auth start=\"true\" users=\"yyq\" passwordfile=\"/etc/rsync_server.pas\"/&gt; &lt;userDefinedPort start=\"false\" port=\"874\"/&gt;&lt;!-- port=874 --&gt; &lt;timeout start=\"false\" time=\"100\"/&gt;&lt;!-- timeout=100 --&gt; &lt;ssh start=\"false\"/&gt; &lt;/rsync&gt; &lt;failLog path=\"/tmp/rsync_fail_log.sh\" timeToExecute=\"60\"/&gt;&lt;!--default every 60mins execute once--&gt; &lt;crontab start=\"false\" schedule=\"600\"&gt;&lt;!--600mins--&gt; &lt;crontabfilter start=\"false\"&gt; &lt;exclude expression=\"*.php\"&gt;&lt;/exclude&gt; &lt;exclude expression=\"info/*\"&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start=\"false\" name=\"command\"/&gt; &lt;/sersync&gt; 启动sersync sersync2 -d -r -o /home/yyq/sersync/confxml.xml 检查同步是否完成 查看同步日志tail -f 100 /var/log/rsync.log 设置sersync监控开机自动执行 vi /etc/rc.d/rc.local #编辑，在最后添加一行 sersync2 -d -r -o /home/yyq/sersync/confxml.xml ＃设置开机自动运行脚本 注意事项 用户认证文件是属于root，因此在运行sersync注意也需要用root去运行，否则会出现同步错误 用户认证文件的文件属性是600 本台机器是在10.0.2.124机器上配置的，在10.0.2.123上配置同这个一样，只需要把ip换成10.0.2.124即可 rsync 用法常用格式 rsync [OPTION]… SRC [SRC]… [USER@]HOST:DEST将本地内容拷贝到远程机器上 rsync [OPTION]… [USER@]HOST::SRC [DEST]将远程机器的内容拷贝到本地 rsync [OPTION]… SRC [SRC]… DEST本地拷贝 rsync [OPTION]… [USER@]HOST::SRC [DEST]从远程rsync服务器中拷贝文件到本地机 rsync [OPTION]… SRC [SRC]… [USER@]HOST::DEST从本地机器拷贝文件到远程rsync服务器中 rsync [OPTION]… rsync://[USER@]HOST[:PORT]/SRC [DEST] 列远程机的文件列表 常用参数 -r 表示递归 ；-l 是链接文件，意思是拷贝链接文件；-p 表示保持文件原有权限； -t 保持文件原有时间；-g 保持文件原有用户组；-o 保持文件原有属主； -z 传输时压缩；-P 传输进度；-e ssh的参数建立起加密的连接 -u只进行更新，防止本地新文件被重写，注意两者机器的时钟的同时 -v 传输时的进度等信息； –progress是指显示出详细的进度情况 –delete是指如果服务器端删除了这一文件，那么客户端也相应把文件删除，保持真正的一致 –password-file=/password/path/file来指定密码文件 –exclude=PATTERN 指定排除不需要传输的文件模式 –include=PATTERN 指定不排除而需要传输的文件模式 –exclude-from=FILE 排除FILE中指定模式的文件 –include-from=FILE 不排除FILE指定模式匹配的文件 –config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件 –ignore-errors 即使出现IO错误也进行删除 –existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件 –delete-excluded 同样删除接收端那些被该选项指定排除的文件 –delete-after 传输结束以后再删除","tags":[{"name":"sersync同步配置","slug":"sersync同步配置","permalink":"http://yqyao.github.io/tags/sersync同步配置/"}]},{"title":"cython-document2","date":"2017-02-03T08:29:27.000Z","path":"2017/02/03/cython-document2/","text":"Using C libraries为了能更高效的利用c的library，cython提供了一套API。用户可以兼顾python开发的高效性与c性能的高效性。下面以cython调用c的queue为例简单介绍。 C的queue 头文件(queue.h)1234567891011121314151617/* file: queue.h */typedef struct _Queue Queue;typedef void *QueueValue;Queue *queue_new(void);void queue_free(Queue *queue);int queue_push_head(Queue *queue, QueueValue data);QueueValue queue_pop_head(Queue *queue);QueueValue queue_peek_head(Queue *queue);int queue_push_tail(Queue *queue, QueueValue data);QueueValue queue_pop_tail(Queue *queue);QueueValue queue_peek_tail(Queue *queue);int queue_is_empty(Queue *queue); 重定义C的头文件（cqueue.pxd） 12345678910111213141516171819# file: cqueue.pxdcdef extern from \"libcalg/queue.h\": ctypedef struct Queue: pass ctypedef void* QueueValue Queue* queue_new() void queue_free(Queue* queue) int queue_push_head(Queue* queue, QueueValue data) QueueValue queue_pop_head(Queue* queue) QueueValue queue_peek_head(Queue* queue) int queue_push_tail(Queue* queue, QueueValue data) QueueValue queue_pop_tail(Queue* queue) QueueValue queue_peek_tail(Queue* queue) bint queue_is_empty(Queue* queue) 对于cython头文件的格式以.pyd的格式存在，对于每一个所用的c library 建立一个.pxd文件是一个非常好的习惯 队列class1234567# file: queue.pyxcimport cqueuecdef class Queue: cdef cqueue.Queue* _c_queue def __cinit__(self): self._c_queue = cqueue.queue_new() 注意如果用了cdef 定义class时，相应了要用cinit()。 内存分配在调用queue_new() 时肯定会分配内存，如果内存不足就会出现错误，因此上面的queue.pyx需要改进,在内存不足时需要报内存错误。12345678cimport cqueuecdef class Queue: cdef cqueue.Queue* _c_queue def __cinit__(self): self._c_queue = cqueue.queue_new() if self._c_queue is NULL: raise MemoryError() 同样的在内存释放时也需要做检查123def __dealloc__(self): if self._c_queue is not NULL: cqueue.queue_free(self._c_queue) 编译和链接 setup.py （不需要加入include） 1234567from distutils.core import setupfrom distutils.extension import Extensionfrom Cython.Build import cythonizesetup( ext_modules = cythonize([Extension(\"queue\", [\"queue.pyx\"])])) 使用c的library 需要加入include 1234ext_modules = cythonize([ Extension(\"queue\", [\"queue.pyx\"], libraries=[\"calg\"]) ]) 运行时指定 include 123CFLAGS=\"-I/usr/local/otherdir/calg/include\" \\LDFLAGS=\"-L/usr/local/otherdir/calg/lib\" \\ python setup.py build_ext -i 映射方法 append() 123cdef append(self, int value): if not cqueue.queue_push_tail(self._c_queue, &lt;void*&gt;value): raise MemoryError() extend() 12345678cdef extend(self, int* values, size_t count): \"\"\"Append all ints to the queue. \"\"\" cdef size_t i for i in range(count): if not cqueue.queue_push_tail( self._c_queue, &lt;void*&gt;values[i]): raise MemoryError() peek() and pop() 12345cdef int peek(self): return &lt;int&gt;cqueue.queue_peek_head(self._c_queue)cdef int pop(self): return &lt;int&gt;cqueue.queue_pop_head(self._c_queue) 注意在append 和 extend 方法中同样也要做None 类型检查，原因同之前 队列为空问题在c中队列为空，peek会返回一个空指针，对应cython中是0，如果队列的元素刚好也为0这样我们就无法分辨，因此我们希望返回的是一个异常。因此第二代版本的peek() 如下12345678cdef int peek(self) except? -1: value = &lt;int&gt;cqueue.queue_peek_head(self._c_queue) if value == 0: # this may mean that the queue is empty, or # that it happens to contain a 0 value if cqueue.queue_is_empty(self._c_queue): raise IndexError(\"Queue is empty\") return value 相应的我们也增加了pop()的第二代版本1234cdef int pop(self) except? -1: if cqueue.queue_is_empty(self._c_queue): raise IndexError(\"Queue is empty\") return &lt;int&gt;cqueue.queue_pop_head(self._c_queue)","tags":[{"name":"cython","slug":"cython","permalink":"http://yqyao.github.io/tags/cython/"}]},{"title":"cython-document1","date":"2017-02-03T06:48:10.000Z","path":"2017/02/03/cython-document1/","text":"cython -Extention types一般的python class123456class MathFunction(object): def __init__(self, name, operator): self.name = name self.operator = operator def __call__(self, *operands): return self.operator(*operands) 普通的python 是用dictionary 去存储class中对象和方法，对于cython可以采用c中的结构体去更加高效的存储 cython class下面是一个简单的cython类的定义123cdef class Function: cpdef double evaluate(self, double x) except *: return 0 我们再定义一个类继承上面的类123cdef class SinOfSquareFunction(Function): cpdef double evaluate(self, double x) except *: return sin(x**2) cpdef 表示python 外部可调用此方法，注意对于cpdef 定义子类会完全重载父类中的方法 简单的例子 cython 格式1234567891011def integrate(Function f, double a, double b, int N): cdef int i cdef double s, dx if f is None: raise ValueError(\"f cannot be None\") s = 0 dx = (b-a)/N for i in range(N): s += f.evaluate(a+i*dx) return s * dxprint(integrate(SinOfSquareFunction(), 0, 1, 10000)) 这是一段简单的cython的代码，我们将通过这个来感受cython带来的速度提升 python 格式123456&gt;&gt;&gt; import integrate&gt;&gt;&gt; class MyPolynomial(integrate.Function):... def evaluate(self, x):... return 2*x*x + 3*x - 10...&gt;&gt;&gt; integrate(MyPolynomial(), 0, 1, 10000) 我们这里直接的生成一个python的类去继承Function这个类，并重载Function的方法 速度差异这种python格式的class 比cython 格式要慢20倍，但是比原生的python还是要快10倍 注意事项 首先Function中必须要声明evaluate方法，否则SinOfSquareFunction中会默认去调python版本的evaluate 参数f 必须要声明类型即Function 参数必须做检查是否为None @cython.nonecheck(False) 可做None 检查但是会消耗一定时间123456789101112import cython# Turn off nonecheck locally for the function@cython.nonecheck(False)def func(): cdef MyClass obj = None try: # Turn nonecheck on again for a block with cython.nonecheck(True): print obj.myfunc() # Raises exception except AttributeError: pass print obj.myfunc() # Hope for a crash! cdef class 属性注意事项 所有属性编译前必须预先声明 属性必须是cython 所允许的 Properties 可以被声明在python 空间中 实例123456789101112cdef class WaveFunction(Function): # Not available in Python-space: cdef double offset # Available in Python-space: cdef public double freq # Available in Python-space: @property def period(self): return 1.0 / self.freq @period.setter def period(self, value): self.freq = 1.0 / value","tags":[{"name":"cython","slug":"cython","permalink":"http://yqyao.github.io/tags/cython/"}]},{"title":"ffmpeg 从视频中截取图像帧","date":"2017-01-07T14:25:39.000Z","path":"2017/01/07/ffmpeg/","text":"ffmpeg 从视频中截取图像帧安装ffmpeg 安装环境centos 7.0 安装命令1yum -y install ffmpeg 使用方法 命令1 1ffmpeg -i inputfile.avi -r 1 -f image2 image-%05d.jpeg -r 指定抽取的帧率，即从视频中每秒钟抽取图片的数量。1代表每秒抽取一帧 -f 指定保存图片使用的格式，可忽略 image-%05d.jpeg，指定文件的输出名字 命令2 1ffmpeg -i inputfile.avi -r 1 -s 4cif -f image2 image-%05d.jpeg 4cif 代表帧的尺寸为705x576.可以显性的设置为705x576 命令3 1ffmpeg -i inputfile.avi -r 1 -t 4 -f image2 image-%05d.jpeg -t 代表持续时间，单位为秒 命令4 1ffmpeg -i inputfile.avi -r 1 -ss 00:1:14 -f image2 image-%05d.jpeg -ss 指定起始时间 命令5 1ffmpeg -i inputfile.avi -r 1 -ss 01:30:14 -vframes 120 4cif -f image2 image-%05d.jpeg -vframes 指定抽取的帧数 命令6 12ffmpeg -i inputfile.avi -r 1 -ss 00:1:14 -f image2 image-%05d.jpegffmpeg -i inputfile.avi -r 1 -ss 00:1:14 -f -vframes 1 image2 image-%05d.jpeg 通过指定-ss，和-vframes也可以达到同样的效果。 这时候-ss参数后跟的时间有两种写法,hh:mm:ss 或 直接写秒数","tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://yqyao.github.io/tags/ffmpeg/"}]},{"title":"cv2_python","date":"2017-01-07T06:54:23.000Z","path":"2017/01/07/cv2-python/","text":"python cv2 连续读图片内存机制由于项目测试需求， 需要连续用cv2读图片，通过htop发现内存不断增长，开始以为是内存泄露。查找了一圈，从可能出现内存泄露的地方开始查起，包括底层调c的模块，以及python部分。发现并没有内存泄露的情况，在测试的过程中发现连续发同一张图片内存不会增长，多张图片就可能会增长。由此我们猜测可能是由于opencv读图片的问题。 验证猜想12345678910import timeimage_list = []import cv2# img_list.txt 里面为图片的文件名with open(\"img_list.txt\", \"r\") as f: for line in f.readlines(): image_list.append(line.strip())for img in image_list[:1000]: cv2.imread(img) time.sleep(0.1) 测试策略如下：每隔0.1秒用opencv读取图片，图片的大小各不相同，用htop观察内存使用情况 测试结果：当读取比较大的图片，内存会增加，再读取较小图片，内存不会增大。 最终猜测结果python cv2 读取连续图片可能的内存机制如下：opencv 在连续读取图片时申请内存会根据读取的最大的图片按需来申请，同时读完后并不会释放，再读取下一张图片时不需要重复的申请内存。如果遇到更大的图片opencv会申请更大的内存。","tags":[{"name":"python","slug":"python","permalink":"http://yqyao.github.io/tags/python/"},{"name":"cv2","slug":"cv2","permalink":"http://yqyao.github.io/tags/cv2/"}]},{"title":"supervisord","date":"2016-12-17T15:04:21.000Z","path":"2016/12/17/supervisord/","text":"Supervisord 使用文档why 用这个？由于项目需求，需要开启大量的Tornado Server因此需要管理这些进程，手动管理很不方便。因此就去google发现在实际中Supervisord可以很好的满足需求 Supervisor介绍Supervisor 是一个 Python 开发的 client/server 系统，可以管理和监控类 UNIX操作系统上面的进程。它可以同时启动，关闭多个进程，使用起来特别的方便 组成部分supervisord(server 部分)：主要负责管理子进程，响应客户端命令以及日志的输出等supervisorctl(client 部分)：命令行客户端，用户可以通过它与不同的 supervisord 进程联系，获取子进程的状态等web 页面部分（其实这个不算是一部分，但是也相对于前面独立） 安装与配置安装pip install supervisor (centos)生成指定的配置文件：echo_supervisord_conf &gt; supervisord.conf 配置[unix_http_server];file=/tmp/supervisor.sock ; (the path to the socket file);修改为 /var/run 目录，避免被系统删除file=/var/run/supervisor.sock ; socket文件的路径，supervisorctl用XML_RPC和supervisord通信就是通过它进行;chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; (default is no username (open server));password=123 ; (default is no password (open server));[inet_http_server] ; inet (TCP) server disabled by default(此项用于web 页面);port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for ;all iface);username=user ; (default is no username (open server));pasword=123 ; (default is no password (open server))… [supervisord] logfile=/home/faceall/supervisord/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/home/faceall/supervisord/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200);umask=022 ; (process file creation umask;default 022);user=chrism ; (default is current user, required if root);identifier=supervisor ; (supervisord identifier, default is ‘supervisor’);directory=/tmp ; (default is not to cd during start);nocleanup=true ; (don’t clean up tempfiles at start;default false);childlogdir=/tmp ; (‘AUTO’ child log dir, default $TEMP);environment=KEY=”value” ; (key value pairs to add to environment);strip_ansi=false ; (strip ansi escape codes in logs; def. false)[supervisorctl]; 必须和’unix_http_server’里面的设定匹配;serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;修改为 /var/run 目录，避免被系统删除serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket（与之前设置一致）;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set[group:tornadoes]programs=tornado-11111 [program:tornado-11111]command=sh start.sh –执行命令directory=/home/faceall/cython-sdk –执行命令的根目录user=faceall –用户autorestart=false –是否自动重启startretries=1 –重启尝试次数redirect_stderr=true –重定向错误stdout_logfile=/home/faceall/cython-sdk/log/tornado_server.log – 日志输出路径loglevel=info –日志输出级别 stopasgroup=true ; (是否kill管理的子进程的子进程)send stop signal to the UNIX process group (default false)killasgroup=true ; SIGKILL the UNIX process group (def false) 命令详解supervisord -c supervisord.conf (以指定路径下的配置文件启动supervisord,此时为当前路径)supervisorctl stop programxxx，停止一个进程supervisorctl start programxxx，开始一个进程supervisorctl restart programxxx，重启一个进程supervisorctl stop groupworker，停止一个组进程supervisorctl stop groupworker：programxxx， 停止一个组中的一个进程supervisorctl stop all，停止所有进程（注：start、restart、stop都不会载入最新的配置文件）supervisorctl reload, 载入最新的配置文件supervisorctl update，根据最新配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响重启 扩展阅读supervisord 只能实现单机的进程管理，如果需要实现多机器同时显示并管理官方推荐有几个开源的项目:NodevisorSupervisord-Monitor","tags":[]},{"title":"cython 基础详解","date":"2016-12-17T14:45:26.000Z","path":"2016/12/17/cython/","text":"Cython helloworld 介绍 首先创建 helloworld.pyx: 12345678910111213141516cdef extern from\"stdio.h\": extern int printf(const char *format, ...) def SayHello(): printf(\"hello,world\\n\")``` * 如何编译：（在helloworld 目录下新建一个setup.py文件）```pythonfrom distutils.core import setupfrom distutils.extension import Extensionfrom Cython.Build import cythonizesetup( name = 'helloworld', ext_modules=cythonize([ Extension(\"helloworld\", [\"helloworld.pyx\"]), ]),) 编译命令： 1python setup.py build 实际效果 123&gt;&gt;&gt;import helloworld &gt;&gt;&gt;helloworld.SayHello() hello,world Cython 类型类型定义 定义一个C变量1234cdef int an[10]cdef int n = 123cdef int *pn = &amp;nprintf(\"%d \\n\",pn[0]) 不同的地方就是在声明的最前面要加上cdef,另外，末尾不用加分号; 定义python变量12b = [1,2,3]a = 'hello,world' 与python无区别 类型转换123cdef float a= 123.456cdef int bb = &lt;int&gt;a 在Cython里用&lt;&gt;替代了()来进行类型转换注意问题：以Cython里不能用类似*ptr这样代码来对指针变量进行取值，而必须用ptr[0]这样的形式 Cython 函数编写 python 方法（add.py） 12345678910111213141516import mathimport timedef big_circle(lon1, lat1, lon2, lat2): radius = 3965 x = math.pi / 180.0 a = (90.0 - lat1) * (x) b = (90.0 - lat2) * (x) theta = (lon2 - lon1) * (x) c = math.acos(math.cos(a) * math.cos(b) + math.sin(a) * math.sin(b)*math.cos(theta)) return c*radiuslon1, lat1, lon2, lat2 = -72.345, 34.323, -61.823, 54.826st = time.time()for i in range(5000000): result = big_circle(lon1, lat1, lon2, lat2)print time.time() - st cython 代码(add.pyx) 12345678910111213141516171819202122cdef extern from \"math.h\": float cosf(float theta) float sinf(float theta) float acosf(float theta)cimport cythonimport timedef big_circle(float lon1,float lat1,float lon2,float lat2): cdef float radius = 3956.0 cdef float pi = 3.14159265 cdef float x = pi/180.0 cdef float a,b,theta,c a = (90.0-lat1)*(x) b = (90.0-lat2)*(x) theta = (lon2-lon1)*(x) c = acosf((cosf(a)*cosf(b)) + (sinf(a)*sinf(b)*cosf(theta))) return radius*c def test_add(): lon1, lat1, lon2, lat2 = -72.345, 34.323, -61.823, 54.826 st = time.time() for i in range(5000000): result = big_circle(lon1, lat1, lon2, lat2) print time.time() - st 注意这里只讨论python 调c的情况 Cython 结构体，枚举等其他类型结构体(1) 123456789cdef struct AB: int a int b def StructTest(): cdef AB ab ab.a = 1 ab.b = 2 return ab 注意：Cython里没有-&gt;的操作符，用”.”替代”-&gt;”Cython里不能用*来对指针变量取值，用[0]替代 结构体(2) 12345678910111213 cdef struct AB: int a int b or ctypedef struct AB: int a int bdef StructTest(): cdef AB ab cdef AB *pAB = &amp;ab pAB.a = 1 pAB.b = 2 return pAB[0] 说明Cython里结构体的定义比较像C++的语法，即在声明一个结构体变量时不用在结构体名前再加上struct关键字在C,C++代码里，返回一个结构体变量时，会把结构体转成Python的dict对象 枚举 123456789cdef enum MyEnum: a b = 2 c = 5 or ctypedef enum MyEnum: a b = 2 c = 5 Cython里调用外部定义的函数和结构体、枚举 1234cdef extern from \"image.h\": ctypedef struct image: unsigned int height; unsigned int width; 注意：定义的结构体以及枚举类型可集中写在一个头文件内，后缀为.pyd Cython 中的类(用法同函数)参考链接","tags":[{"name":"cython","slug":"cython","permalink":"http://yqyao.github.io/tags/cython/"}]}]